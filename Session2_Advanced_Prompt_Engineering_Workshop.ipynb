{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586692fb",
   "metadata": {},
   "source": [
    "# üöÄ Session 2: Advanced Prompt Engineering Workshop (Week 2)\n",
    "\n",
    "## **Welcome to the Ultimate Prompt Engineering Experience!** üéØ\n",
    "\n",
    "### What You'll Master Today:\n",
    "- üß† **Chain-of-Thought (CoT)**: Make AI think step-by-step like a human\n",
    "- üìö **Few-Shot Learning**: Teach AI by example\n",
    "- üé≠ **Role-Based Prompting**: Transform AI into any expert you need\n",
    "- üõ†Ô∏è **Robust Templates**: Build reusable, production-ready prompts\n",
    "- üêõ **Debugging**: Fix common prompt failures like a pro\n",
    "- ü§ñ **Agentic Frameworks**: Create intelligent AI agents with LangChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0354f3",
   "metadata": {},
   "source": [
    "## üì¶ Part 1: Environment Setup & Dependencies\n",
    "\n",
    "### **Why These Libraries?**\n",
    "- **OpenAI**: Access to GPT models for natural language processing\n",
    "- **LangChain**: The Swiss Army knife for prompt engineering and agent development\n",
    "- **Python-dotenv**: Secure API key management\n",
    "- **Colorama**: Make our outputs beautiful and easy to read!\n",
    "\n",
    "Let's install everything we need for an amazing workshop experience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100eb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All packages installed successfully!\n",
      "üì¶ Installed packages:\n",
      "  - langchain - Main framework\n",
      "  - langchain-openai - OpenAI integration\n",
      "  - langchain-community - Community integrations\n",
      "  - openai (latest) - OpenAI API client\n",
      "  - python-dotenv - Environment variable management\n",
      "  - colorama - Colored terminal output\n",
      "  - tiktoken - Token counting utility\n"
     ]
    }
   ],
   "source": [
    "# Install required packages with latest versions (as of 2024)\n",
    "# Using latest stable versions for production reliability\n",
    "\n",
    "!pip install -q -U langchain langchain-openai langchain-community\n",
    "!pip install -q -U openai python-dotenv colorama tiktoken\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")\n",
    "print(\"üì¶ Installed packages:\")\n",
    "print(\"  - langchain - Main framework\")\n",
    "print(\"  - langchain-openai - OpenAI integration\")\n",
    "print(\"  - langchain-community - Community integrations\")\n",
    "print(\"  - openai (latest) - OpenAI API client\")\n",
    "print(\"  - python-dotenv - Environment variable management\")\n",
    "print(\"  - colorama - Colored terminal output\")\n",
    "print(\"  - tiktoken - Token counting utility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e3d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain modules imported successfully!\n",
      "üéâ Workshop environment ready!\n",
      "üí° Tip: Use pretty_print() for formatted output\n",
      "üîß Helper functions loaded: pretty_print, safe_input, validate_api_key\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries with error handling\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "from typing import List, Dict, Any, Optional\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "try:\n",
    "    # LangChain imports\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain.prompts import (\n",
    "        PromptTemplate, \n",
    "        ChatPromptTemplate, \n",
    "        FewShotPromptTemplate,\n",
    "        FewShotChatMessagePromptTemplate\n",
    "    )\n",
    "    from langchain.chains import LLMChain\n",
    "    from langchain.schema import BaseOutputParser\n",
    "    from langchain.memory import ConversationBufferMemory\n",
    "    from langchain.agents import initialize_agent, Tool, AgentType\n",
    "    from langchain.callbacks import StdOutCallbackHandler\n",
    "    \n",
    "    print(\"‚úÖ LangChain modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"Please ensure all packages are installed correctly.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Initialize colorama for colored output\n",
    "init(autoreset=True)\n",
    "\n",
    "# Helper functions for the workshop\n",
    "def pretty_print(title: str, content: str, color=Fore.CYAN):\n",
    "    \"\"\"Pretty print with colored headers\"\"\"\n",
    "    print(f\"\\n{color}{'='*60}\")\n",
    "    print(f\"{Style.BRIGHT}{title}\")\n",
    "    print(f\"{'='*60}{Style.RESET_ALL}\")\n",
    "    print(content)\n",
    "    print(f\"{color}{'='*60}{Style.RESET_ALL}\\n\")\n",
    "\n",
    "def safe_input(prompt: str, default: str = \"\") -> str:\n",
    "    \"\"\"Safe input handling for interactive sections\"\"\"\n",
    "    try:\n",
    "        return input(prompt) or default\n",
    "    except (EOFError, KeyboardInterrupt):\n",
    "        return default\n",
    "\n",
    "def validate_api_key(api_key: str) -> bool:\n",
    "    \"\"\"Validate OpenAI API key format\"\"\"\n",
    "    return api_key.startswith('sk-') and len(api_key) > 20\n",
    "\n",
    "print(\"üéâ Workshop environment ready!\")\n",
    "print(\"üí° Tip: Use pretty_print() for formatted output\")\n",
    "print(\"üîß Helper functions loaded: pretty_print, safe_input, validate_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da766e1d",
   "metadata": {},
   "source": [
    "## üîë Part 2: Secure API Configuration\n",
    "\n",
    "### **Security Best Practice Alert!** üîí\n",
    "Never hardcode API keys in your notebooks! We'll use secure methods to manage credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb965e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key already configured!\n",
      "üîÑ Testing connection to OpenAI...\n",
      "üöÄ GPT-4 Model initialized successfully!\n",
      "ü§ñ AI says: Hello Workshop!\n",
      "\n",
      "üìä Model Configuration:\n",
      "  - Model: GPT-4\n",
      "  - Temperature: 0.7 (balanced creativity)\n",
      "  - Max Tokens: 1000\n",
      "  - Timeout: 30 seconds\n"
     ]
    }
   ],
   "source": [
    "# Secure API key setup with validation and error handling\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to load from .env file first\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is already set\n",
    "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
    "    print(\"üîê Let's set up your OpenAI API key securely...\")\n",
    "    print(\"üìù Get your API key from: https://platform.openai.com/api-keys\")\n",
    "    \n",
    "    while True:\n",
    "        api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "        if validate_api_key(api_key):\n",
    "            os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "            print(\"‚úÖ API key configured successfully!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid API key format. Please try again.\")\n",
    "else:\n",
    "    print(\"‚úÖ API key already configured!\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",  # Using GPT-4 for advanced reasoning\n",
    "        temperature=0.7,  # Balance between creativity and consistency\n",
    "        max_tokens=1000,  # Longer responses for detailed explanations\n",
    "        request_timeout=30,  # 30 second timeout\n",
    "        max_retries=2  # Retry failed requests\n",
    "    )\n",
    "    \n",
    "    # Test the connection with a simple query\n",
    "print(\"üîÑ Testing connection to OpenAI...\")\n",
    "test_response = llm.invoke(\"Say 'Hello Workshop!' if you're ready\")\n",
    "print(\"üöÄ GPT-4 Model initialized successfully!\")\n",
    "print(f\"ü§ñ AI says: {test_response.content}\")\n",
    "    \n",
    "# Display model configuration\n",
    "print(\"\\nüìä Model Configuration:\")\n",
    "print(f\"  - Model: GPT-4\")\n",
    "print(f\"  - Temperature: 0.7 (balanced creativity)\")\n",
    "print(f\"  - Max Tokens: 1000\")\n",
    "print(f\"  - Timeout: 30 seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fcddce",
   "metadata": {},
   "source": [
    "## üéØ Part 3: Understanding AI Agents & LangChain Fundamentals\n",
    "\n",
    "### **What is an AI Agent?** ü§ñ\n",
    "An AI agent is an autonomous system that can:\n",
    "- **Perceive** its environment (understand user input)\n",
    "- **Reason** about what to do (use prompts to think)\n",
    "- **Act** to achieve goals (execute tasks)\n",
    "- **Learn** from interactions (improve over time)\n",
    "\n",
    "### **Why LangChain?** üîó\n",
    "LangChain provides:\n",
    "- **Modular components** for building AI applications\n",
    "- **Chains** to link prompts and models\n",
    "- **Memory** to maintain conversation context\n",
    "- **Tools** for agents to interact with external systems\n",
    "\n",
    "Let's build our first intelligent agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6afe439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22858/312574894.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  basic_chain = LLMChain(llm=llm, prompt=basic_prompt, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Let's explore: Super Computers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22858/312574894.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = basic_chain.run(topic=topic)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üß† AI Explains: SUPER COMPUTERS\n",
      "============================================================\n",
      "Sure! Let‚Äôs dive into the fascinating world of supercomputers with an analogy that‚Äôs both fun and relatable.\n",
      "\n",
      "**Imagine a Supercharged Brain! üß†‚ö°**\n",
      "\n",
      "Think of your brain as a regular computer. It can solve problems, remember things, and even multitask, but it has its limits ‚Äì like when you try to juggle too many tasks at once and your brain starts to feel like a traffic jam! üö¶\n",
      "\n",
      "Now, picture a supercomputer as a supercharged brain on steroids! It‚Äôs like having a team of thousands of tiny brains all working together, each one dedicated to solving a specific part of a gigantic puzzle. Let‚Äôs break it down:\n",
      "\n",
      "1. **Speed**: If your brain processes information at the speed of a bicycle, a supercomputer is like a Formula 1 race car zooming at lightning speed! It can perform trillions of calculations per second. Imagine trying to solve a Rubik's Cube ‚Äì while you might take a few minutes, a supercomputer could do it in a fraction of a second!\n",
      "\n",
      "2. **Parallel Processing**: Think of a group of friends trying to put together a massive jigsaw puzzle. One friend focuses on the edge pieces, another on the blue sky, and another on the green grass. Together, they finish the puzzle way faster than if just one person was doing it alone. Supercomputers work in the same way ‚Äì they can tackle multiple tasks at the same time by breaking them into smaller chunks and processing them simultaneously.\n",
      "\n",
      "3. **Complex Problems**: Let‚Äôs say you‚Äôre trying to predict the weather for your weekend trip. Your brain can make a guess based on what you see out the window, but a supercomputer can crunch vast amounts of data, analyze patterns, and even simulate future weather conditions. It‚Äôs like having a crystal ball that‚Äôs supercharged with real-time data and scientific models!\n",
      "\n",
      "4. **Applications**: Supercomputers aren‚Äôt just for fun and games; they‚Äôre used for serious stuff! Think about how they help scientists discover new medicines or how they simulate nuclear reactions to keep us safe. They can even model climate change to help save our planet. It‚Äôs like having a superhero sidekick for researchers and engineers, helping them solve the world‚Äôs biggest challenges!\n",
      "\n",
      "So, the next time you hear about supercomputers, just remember: they‚Äôre like the ultimate brain team, turbocharged to tackle the most complex problems faster than you can say ‚Äúsupercalifragilisticexpialidocious!‚Äù Whether it‚Äôs saving lives, predicting the future, or cracking the mysteries of the universe, supercomputers are at the forefront of innovation, making our world a better place ‚Äì one calculation at a time! üåç‚ú®\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéÆ YOUR TURN! Enter a topic you'd like explained:\n",
      "(Press Enter to skip)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Topic:  Sigmoid function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing your topic: Sigmoid function...\n",
      "\n",
      "============================================================\n",
      "üß† AI Explains: SIGMOID FUNCTION\n",
      "============================================================\n",
      "Sure! Let‚Äôs dive into the world of the sigmoid function, but first, let‚Äôs set the stage with a fun analogy!\n",
      "\n",
      "**Imagine a Roller Coaster! üé¢**\n",
      "\n",
      "Picture yourself at an amusement park, standing in line for a magnificent roller coaster. You‚Äôre filled with excitement and a hint of nervousness. As you buckle in, the ride starts to climb slowly, giving you a chance to enjoy the view. That initial ascent represents the first part of the sigmoid function, where the output is gradually increasing but still pretty low ‚Äì just like your anticipation!\n",
      "\n",
      "Now, once you reach the top, the ride suddenly plummets! Your adrenaline spikes, and you feel like you‚Äôre flying. In the sigmoid function, this corresponds to the steep middle section where the output shoots up rapidly. This is the thrilling part where everything changes, and you can‚Äôt help but scream in delight (or fright)!\n",
      "\n",
      "Finally, as the roller coaster begins to slow down and level off, you glide back into the station, feeling a sense of calm. This represents the last part of the sigmoid function, where the output levels off again, approaching a maximum value but never quite reaching it‚Äîjust like your excitement settling after the ride!\n",
      "\n",
      "**So, What Is the Sigmoid Function? ü§î**\n",
      "\n",
      "The sigmoid function is a mathematical function that has an S-shaped curve (hence the name sigmoid). It‚Äôs defined by the formula:\n",
      "\n",
      "\\[ S(x) = \\frac{1}{1 + e^{-x}} \\]\n",
      "\n",
      "where \\( e \\) is a mathematical constant (approximately 2.718). It takes any real number input (like the height of that roller coaster) and squashes it between 0 and 1, just like how your emotions are squashed into that thrill-seeking roller coaster experience!\n",
      "\n",
      "**Why Is It Important? üåü**\n",
      "\n",
      "1. **In Machine Learning:** The sigmoid function is often used in logistic regression and neural networks because it helps model probabilities. Just like how your thrill level ranges from calm (0) to ecstatic (1), the sigmoid function helps predict outcomes that are binary (like yes/no or win/lose).\n",
      "\n",
      "2. **In Biology:** The sigmoid function can model growth processes. For example, think of a population of rabbits. At first, they grow slowly (just like that first climb on the coaster), then rapidly multiply (the thrilling drop), and finally, they stabilize when resources become limited (the smooth return to the station).\n",
      "\n",
      "**In Summary: üéâ**\n",
      "\n",
      "The sigmoid function is like a roller coaster ride for numbers! It starts off slow, zooms up in excitement, and then levels out, capturing the thrill of change. Whether you‚Äôre predicting probabilities or modeling growth, this little mathematical gem helps us understand the ups and downs of life, much like our favorite amusement park rides!\n",
      "\n",
      "So, next time you hear about the sigmoid function, just think of that exhilarating roller coaster experience and the fun journey of numbers! üé¢‚ú®\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üé¨ Your First AI Agent - The Basics\n",
    "\n",
    "# Create a simple prompt template\n",
    "basic_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"\"\"You are a helpful AI assistant. \n",
    "    \n",
    "    Please explain the following topic in a fun and engaging way:\n",
    "    Topic: {topic}\n",
    "    \n",
    "    Make it interesting with an analogy or example!\"\"\"\n",
    ")\n",
    "\n",
    "# Create a chain (connecting prompt to model)\n",
    "try:\n",
    "    basic_chain = LLMChain(llm=llm, prompt=basic_prompt, verbose=False)\n",
    "    \n",
    "    # Test our agent with a fun topic\n",
    "    topic = \"Super Computers\"\n",
    "    print(f\"üéØ Let's explore: {topic}\\n\")\n",
    "    \n",
    "    response = basic_chain.run(topic=topic)\n",
    "    \n",
    "    pretty_print(\n",
    "        f\"üß† AI Explains: {topic.upper()}\", \n",
    "        response,\n",
    "        Fore.GREEN\n",
    "    )\n",
    "    \n",
    "    # Interactive element - try your own topic!\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéÆ YOUR TURN! Enter a topic you'd like explained:\")\n",
    "    print(\"(Press Enter to skip)\")\n",
    "    \n",
    "    user_topic = safe_input(\"Topic: \")\n",
    "    if user_topic:\n",
    "        print(f\"\\nüîÑ Processing your topic: {user_topic}...\")\n",
    "        user_response = basic_chain.run(topic=user_topic)\n",
    "        pretty_print(f\"üß† AI Explains: {user_topic.upper()}\", user_response, Fore.MAGENTA)\n",
    "    else:\n",
    "        print(\"‚è≠Ô∏è Skipping interactive section\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error running basic chain: {e}\")\n",
    "    print(\"Please check your API key and connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4c402",
   "metadata": {},
   "source": [
    "## üß† Part 4: Chain-of-Thought (CoT) Prompting - Make AI Think Like a Human!\n",
    "\n",
    "### **What is Chain-of-Thought?** \n",
    "CoT prompting is like giving AI a **thinking process**. Instead of jumping to conclusions, the AI:\n",
    "1. **Breaks down** complex problems\n",
    "2. **Shows its work** step by step\n",
    "3. **Arrives at better answers** through reasoning\n",
    "\n",
    "### **When to Use CoT?** \n",
    "- üßÆ **Math problems** (calculations, word problems)\n",
    "- üîç **Logical reasoning** (puzzles, deductions)\n",
    "- üìä **Analysis tasks** (data interpretation, comparisons)\n",
    "- üéØ **Multi-step problems** (planning, sequences)\n",
    "- üé® **Creative tasks** (story plotting, recipe creation)\n",
    "- üîß **Debugging code** (finding errors systematically)\n",
    "\n",
    "### **The Magic Phrases:** ‚ú®\n",
    "- \"Let's think step by step\"\n",
    "- \"Break this down into parts\"\n",
    "- \"First..., Second..., Finally...\"\n",
    "- \"Consider all aspects before answering\"\n",
    "\n",
    "### **CoT Variations:**\n",
    "1. **Zero-Shot CoT**: Just add \"think step by step\" - no examples needed!\n",
    "2. **Few-Shot CoT**: Provide examples of step-by-step reasoning\n",
    "3. **Self-Consistency CoT**: Generate multiple reasoning paths and vote\n",
    "4. **Tree of Thoughts**: Explore different reasoning branches\n",
    "\n",
    "### **Fun Fact!** üéâ\n",
    "Studies show CoT can improve AI accuracy by up to 30% on complex tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4ceed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Testing the same problem with different approaches:\n",
      "\n",
      "Problem: Four people‚ÄîAnna, Ben, Carla, and David‚Äîeach live in a different colored house: red, blue, green, or yellow.  \n",
      "- Anna does not live in the red or blue house.  \n",
      "- The person in the green house owns a fish.  \n",
      "- Ben lives next to the person in the red house.  \n",
      "- Carla lives in the yellow house.  \n",
      "- David does not live next to Carla.  \n",
      "Who lives in each house, and who owns the fish?\n",
      "\n",
      "‚ùå WITHOUT Chain-of-Thought:\n",
      "To solve the problem, let's summarize the clues and deduce the information step by step:\n",
      "\n",
      "1. **Anna does not live in the red or blue house.** This means Anna must live in the green or yellow house.\n",
      "   \n",
      "2. **The person in the green house owns a fish.** This indicates that whoever lives in the green house has a fish.\n",
      "   \n",
      "3. **Ben lives next to the person in the red house.** This means Ben cannot live in the red house; he must be either to the left or right of the red house.\n",
      "\n",
      "4. **Carla lives in the yellow house.** This means Carla cannot live in the red, blue, or green houses.\n",
      "\n",
      "5. **David does not live next to Carla.** Since Carla lives in the yellow house, David cannot live in either the house to the left or the right of the yellow house.\n",
      "\n",
      "Now, let's begin assigning the houses based on the deductions:\n",
      "\n",
      "- Since Carla lives in the yellow house, Anna cannot live there. Therefore, Anna must be in the green house.\n",
      "  \n",
      "- Since Anna is in the green house, she owns the fish (from clue 2).\n",
      "\n",
      "- Now we know:\n",
      "    - Anna: Green house (fish)\n",
      "    - Carla: Yellow house\n",
      "\n",
      "- Since Ben lives next to the person in the red house (clue 3), and Anna is in green and Carla is in yellow, Ben must be in the blue house. Therefore, the only house left for David is the red house.\n",
      "\n",
      "Putting it all together:\n",
      "- Anna lives in the green house and owns the fish.\n",
      "- Ben lives in the blue house.\n",
      "- Carla lives in the yellow house.\n",
      "- David lives in the red house.\n",
      "\n",
      "Final assignments:\n",
      "- Anna: Green house (fish)\n",
      "- Ben: Blue house\n",
      "- Carla: Yellow house\n",
      "- David: Red house\n",
      "\n",
      "Thus, Anna lives in the green house and owns the fish.\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚úÖ WITH Chain-of-Thought:\n",
      "To solve this problem, let's follow the steps outlined:\n",
      "\n",
      "### Step 1: Identify what we know\n",
      "1. **Anna** does not live in the **red** or **blue** house.\n",
      "2. The person in the **green** house owns a **fish**.\n",
      "3. **Ben** lives next to the person in the **red** house.\n",
      "4. **Carla** lives in the **yellow** house.\n",
      "5. **David** does not live next to **Carla**.\n",
      "\n",
      "### Step 2: Divide it into smaller manageable components\n",
      "- We have four colors: **red**, **blue**, **green**, **yellow**.\n",
      "- We have four people: **Anna**, **Ben**, **Carla**, and **David**.\n",
      "- We need to determine which person lives in which colored house and who owns the fish.\n",
      "\n",
      "### Step 3: Determine what we need to find\n",
      "We need to assign each person to a colored house and identify who owns the fish.\n",
      "\n",
      "### Step 4: Choose the right approach\n",
      "We'll use a process of elimination based on the clues provided.\n",
      "\n",
      "### Step 5: Solve step by step\n",
      "1. **From clue 4**, we know:\n",
      "   - **Carla** lives in the **yellow** house.\n",
      "   - This means the remaining houses for Anna, Ben, and David are **red**, **blue**, and **green**.\n",
      "\n",
      "2. **From clue 1**, since Anna does not live in the **red** or **blue** house:\n",
      "   - Anna must live in the **green** house.\n",
      "\n",
      "3. **From clue 2**, the person in the **green** house owns a **fish**:\n",
      "   - Therefore, Anna owns the **fish**.\n",
      "\n",
      "4. At this point, we have:\n",
      "   - Anna: Green house (with fish)\n",
      "   - Carla: Yellow house\n",
      "   - Remaining houses: Red and Blue for Ben and David.\n",
      "\n",
      "5. **From clue 3**, Ben lives next to the person in the **red** house:\n",
      "   - Since Anna is in the green house and Carla is in the yellow house, Ben must live in the **blue** house. This means David must live in the **red** house.\n",
      "\n",
      "6. Now we summarize:\n",
      "   - Anna: Green house (with fish)\n",
      "   - Ben: Blue house\n",
      "   - Carla: Yellow house\n",
      "   - David: Red house\n",
      "\n",
      "### Final Assignment\n",
      "- **Anna** lives in the **green** house and owns the **fish**.\n",
      "- **Ben** lives in the **blue** house.\n",
      "- **Carla** lives in the **yellow** house.\n",
      "- **David** lives in the **red** house.\n",
      "\n",
      "### Conclusion\n",
      "- **Anna** - Green house (fish)\n",
      "- **Ben** - Blue house\n",
      "- **Carla** - Yellow house\n",
      "- **David** - Red house\n",
      "\n",
      "üí° Notice how CoT catches the trick in the question!\n"
     ]
    }
   ],
   "source": [
    "# üßÆ Chain-of-Thought Example 1: Math Problem Solving\n",
    "\n",
    "# Without CoT - Often gets complex problems wrong\n",
    "simple_prompt = PromptTemplate(\n",
    "    input_variables=[\"problem\"],\n",
    "    template=\"Solve this problem: {problem}\"\n",
    ")\n",
    "\n",
    "# With CoT - Much better accuracy!\n",
    "cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"problem\"],\n",
    "    template=\"\"\"Solve this problem step by step.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Let's think through this carefully:\n",
    "1. First, identify what we know\n",
    "2. divide it into smaller managable and independent components\n",
    "3. Then, determine what we need to find\n",
    "4. Next, choose the right approach\n",
    "5. Finally, solve step by step\n",
    "\n",
    "Solution:\"\"\"\n",
    ")\n",
    "\n",
    "# Create chains\n",
    "simple_chain = LLMChain(llm=llm, prompt=simple_prompt)\n",
    "cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n",
    "\n",
    "# Test with a tricky problem\n",
    "problem = '''Four people‚ÄîAnna, Ben, Carla, and David‚Äîeach live in a different colored house: red, blue, green, or yellow.  \n",
    "- Anna does not live in the red or blue house.  \n",
    "- The person in the green house owns a fish.  \n",
    "- Ben lives next to the person in the red house.  \n",
    "- Carla lives in the yellow house.  \n",
    "- David does not live next to Carla.  \n",
    "Who lives in each house, and who owns the fish?'''\n",
    "\n",
    "print(\"üéØ Testing the same problem with different approaches:\\n\")\n",
    "print(f\"Problem: {problem}\\n\")\n",
    "\n",
    "# Without CoT\n",
    "print(Fore.RED + \"‚ùå WITHOUT Chain-of-Thought:\")\n",
    "simple_response = simple_chain.run(problem=problem)\n",
    "print(simple_response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# With CoT\n",
    "print(Fore.GREEN + \"‚úÖ WITH Chain-of-Thought:\")\n",
    "cot_response = cot_chain.run(problem=problem)\n",
    "print(cot_response)\n",
    "\n",
    "print(\"\\n\" + Fore.YELLOW + \"üí° Notice how CoT catches the trick in the question!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vak1ft5hg78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Logic Puzzle Challenge:\n",
      "\n",
      "\n",
      "============================================================\n",
      "üîç AI's Logical Reasoning\n",
      "============================================================\n",
      "Let's analyze the scenario step by step.\n",
      "\n",
      "### Step 1: Identify all the given facts\n",
      "1. **Alice is allergic to fur.** This means Alice cannot have a dog (which has fur) or a cat (which also has fur). Therefore, Alice must have the bird.\n",
      "   \n",
      "2. **Bob's pet can fly.** The only pet mentioned that can fly is a bird. However, since we have already deduced that Alice has the bird, Bob cannot have the bird. Therefore, Bob cannot have the bird and must have the dog or cat. Since the bird is already assigned to Alice, Bob must have the dog (as the cat is not a flying pet).\n",
      "\n",
      "3. **Charlie doesn't like birds.** Since Alice has the bird, this fact aligns with our previous deduction. Charlie, who does not like birds, cannot have the bird, confirming that Alice has it. \n",
      "\n",
      "### Step 2: List any assumptions or constraints\n",
      "- Alice cannot have a dog or a cat due to her allergy to fur.\n",
      "- Bob must have a pet that can fly, but he cannot have the bird (since it is with Alice).\n",
      "- Charlie cannot have the bird because he doesn't like birds.\n",
      "\n",
      "### Step 3: Apply logical rules\n",
      "From the above deductions, we establish:\n",
      "- **Alice = Bird** (because she is allergic to fur)\n",
      "- **Bob = Dog** (because he must have a pet that can fly, and the bird is with Alice)\n",
      "- **Charlie = Cat** (by elimination, since the bird is with Alice and the dog is with Bob)\n",
      "\n",
      "### Step 4: Check for any contradictions\n",
      "- Alice having the bird does not contradict her allergy (as birds do not have fur).\n",
      "- Bob having the dog does not contradict any of the provided information.\n",
      "- Charlie having the cat does not contradict his dislike for birds.\n",
      "\n",
      "All statements hold true with the assignments we have made, and there are no contradictions.\n",
      "\n",
      "### Step 5: Draw a conclusion\n",
      "Based on the logical reasoning above, we can conclude:\n",
      "- **Alice has the bird.**\n",
      "- **Bob has the dog.**\n",
      "- **Charlie has the cat.**\n",
      "\n",
      "This assignment satisfies all the conditions and constraints provided in the scenario.\n",
      "============================================================\n",
      "\n",
      "\n",
      "üéÆ Try your own logic puzzle!\n",
      "Enter a scenario that requires logical reasoning:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Scenario:  \n"
     ]
    }
   ],
   "source": [
    "# üîç Chain-of-Thought Example 2: Logical Reasoning\n",
    "\n",
    "# Advanced CoT template for complex reasoning\n",
    "advanced_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"scenario\"],\n",
    "    template=\"\"\"You are a logical reasoning expert. Analyze this scenario step by step.\n",
    "\n",
    "Scenario: {scenario}\n",
    "\n",
    "Step-by-step analysis:\n",
    "1. Identify all the given facts\n",
    "2. List any assumptions or constraints\n",
    "3. Apply logical rules\n",
    "4. Check for any contradictions\n",
    "5. Draw a conclusion\n",
    "\n",
    "Detailed reasoning:\"\"\"\n",
    ")\n",
    "\n",
    "reasoning_chain = LLMChain(llm=llm, prompt=advanced_cot_prompt)\n",
    "\n",
    "# Test with a logic puzzle\n",
    "scenario = \"\"\"\n",
    "Three friends - Alice, Bob, and Charlie - each have a different pet: a cat, a dog, or a bird.\n",
    "- Alice is allergic to fur\n",
    "- Bob's pet can fly\n",
    "- Charlie doesn't like birds\n",
    "Who has which pet?\n",
    "\"\"\"\n",
    "\n",
    "print(\"üß© Logic Puzzle Challenge:\\n\")\n",
    "reasoning_response = reasoning_chain.run(scenario=scenario)\n",
    "pretty_print(\"üîç AI's Logical Reasoning\", reasoning_response, Fore.CYAN)\n",
    "\n",
    "# Interactive logic puzzle\n",
    "print(\"\\nüéÆ Try your own logic puzzle!\")\n",
    "print(\"Enter a scenario that requires logical reasoning:\")\n",
    "user_scenario = input(\"Scenario: \")\n",
    "if user_scenario:\n",
    "    user_reasoning = reasoning_chain.run(scenario=user_scenario)\n",
    "    pretty_print(\"üîç AI Solves Your Puzzle\", user_reasoning, Fore.MAGENTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "g8g619be7jv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé™ FUN COT CHALLENGES!\n",
      "\n",
      "Watch how Chain-of-Thought tackles these creative problems:\n",
      "\n",
      "üéØ Challenge: You need to move a piano to the 10th floor but the elevator is broken \n",
      "    and the stairs are too narrow. What do you do?\n",
      "\n",
      "\n",
      "============================================================\n",
      "üß† AI's Creative Solution\n",
      "============================================================\n",
      "Let's work through this systematically:\n",
      "\n",
      "**1. Core Challenge:**  \n",
      "Moving a piano to the 10th floor without a working elevator and with narrow stairs that can't accommodate the piano directly.\n",
      "\n",
      "**2. Available Resources and Constraints:**  \n",
      "- Resources: The piano, the building's staircase, possibly tools (e.g., dollies, straps), and personnel (helpers).  \n",
      "- Constraints: Narrow stairs, the size and weight of the piano, limited access points, safety considerations.\n",
      "\n",
      "**3. Brainstorm Creative Solutions:**  \n",
      "- **Disassemble the Piano:** If possible, take the piano apart into smaller sections or components (e.g., removing the legs or keyboard) to make it easier to carry.  \n",
      "- **Use Alternative Lifting Devices:** Employ specialized equipment like a furniture lift, scaffoldings, or temporary ramps.  \n",
      "- **Build a Custom Railing or Track System:** Create a temporary inclined plane or track along the staircase to slide the piano up.  \n",
      "- **Use a Pulley System:** Install a pulley or block-and-tackle system from the top floor or window to hoist the piano up.  \n",
      "- **Leverage External Access:** If the building has balconies or external windows, consider bringing the piano in through an open window using a crane or pulley.  \n",
      "- **Create a Sled or Rolling Platform:** Place the piano on a sturdy, wheeled platform or sled, then slide it carefully up the stairs with multiple helpers.  \n",
      "- **Coordinate with a Professional Moving Service:** They may have specialized equipment or techniques for tight spaces and heavy items.\n",
      "\n",
      "**4. Evaluate Feasibility:**  \n",
      "- Disassembling the piano is often the safest and most practical first step; many pianos can be taken apart into manageable parts.  \n",
      "- Using a pulley system or external access might be viable if the building allows it and safety measures are in place.  \n",
      "- Building a ramp or sliding track requires time and stability but could be effective if space permits.  \n",
      "- External lifting via crane or window access involves permits and safety considerations but can be the most efficient for very heavy or bulky pianos.\n",
      "\n",
      "**5. Recommended Approach with Reasoning:**  \n",
      "**Disassemble the piano into smaller parts, then carefully carry or slide each piece up the stairs with multiple helpers.**  \n",
      "- This minimizes the risk and physical strain.  \n",
      "- It adapts to narrow stairs since smaller parts are easier to maneuver.  \n",
      "- Once all parts are on the 10th floor, reassemble the piano carefully.  \n",
      "\n",
      "**Additional step:**  \n",
      "If disassembly isn't sufficient or feasible, consider **installing a temporary pulley system from the top floor or window** to hoist the heaviest parts, combined with disassembly.  \n",
      "\n",
      "**Summary:**  \n",
      "Start by disassembling the piano into manageable sections, then use multiple helpers to carry or slide the parts up the narrow stairs. If needed, supplement this with a pulley system or external access methods. This approach balances safety, practicality, and creativity to solve the core challenge effectively.\n",
      "============================================================\n",
      "\n",
      "\n",
      "üí° IMPLEMENTATION TIP:\n",
      "For best results with CoT:\n",
      "‚Ä¢ Use numbered steps (1, 2, 3...)\n",
      "‚Ä¢ Include 'verification' or 'double-check' steps\n",
      "‚Ä¢ Ask for pros/cons analysis for decisions\n",
      "‚Ä¢ Request alternative approaches when applicable\n"
     ]
    }
   ],
   "source": [
    "# üé™ Chain-of-Thought Example 3: Fun Real-World Scenarios\n",
    "\n",
    "# CoT for Creative Problem Solving\n",
    "creative_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"scenario\"],\n",
    "    template=\"\"\"You are a creative problem solver. Use chain-of-thought reasoning.\n",
    "\n",
    "Scenario: {scenario}\n",
    "\n",
    "Let's approach this step-by-step:\n",
    "1. Identify the core challenge\n",
    "2. List available resources and constraints\n",
    "3. Brainstorm creative solutions\n",
    "4. Evaluate each solution's feasibility\n",
    "5. Recommend the best approach with reasoning\n",
    "\n",
    "Creative Solution:\"\"\"\n",
    ")\n",
    "\n",
    "creative_chain = LLMChain(llm=llm, prompt=creative_cot_prompt)\n",
    "\n",
    "# Fun real-world scenarios\n",
    "fun_scenarios = [\n",
    "    \"\"\"You're organizing a surprise party but the birthday person is a detective who \n",
    "    notices everything. How do you keep it secret?\"\"\",\n",
    "    \n",
    "    \"\"\"You need to move a piano to the 10th floor but the elevator is broken \n",
    "    and the stairs are too narrow. What do you do?\"\"\",\n",
    "    \n",
    "    \"\"\"You're cooking dinner for 20 people but only have 2 burners and 1 hour. \n",
    "    How do you make it work?\"\"\"\n",
    "]\n",
    "\n",
    "print(\"üé™ FUN COT CHALLENGES!\\n\")\n",
    "print(\"Watch how Chain-of-Thought tackles these creative problems:\\n\")\n",
    "\n",
    "import random\n",
    "selected_scenario = random.choice(fun_scenarios)\n",
    "print(f\"üéØ Challenge: {selected_scenario}\\n\")\n",
    "\n",
    "solution = creative_chain.run(scenario=selected_scenario)\n",
    "pretty_print(\"üß† AI's Creative Solution\", solution, Fore.YELLOW)\n",
    "\n",
    "# Practical Implementation Tip\n",
    "print(\"\\nüí° IMPLEMENTATION TIP:\")\n",
    "print(\"For best results with CoT:\")\n",
    "print(\"‚Ä¢ Use numbered steps (1, 2, 3...)\")\n",
    "print(\"‚Ä¢ Include 'verification' or 'double-check' steps\")\n",
    "print(\"‚Ä¢ Ask for pros/cons analysis for decisions\")\n",
    "print(\"‚Ä¢ Request alternative approaches when applicable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca8b06",
   "metadata": {},
   "source": [
    "## üìö Part 5: Few-Shot Learning - Teaching by Example\n",
    "\n",
    "### **What is Few-Shot Learning?** \n",
    "Few-shot learning is like **teaching by showing examples**. Instead of explaining rules, you:\n",
    "- üìù **Provide 2-5 examples** of input-output pairs\n",
    "- üéØ **Let the AI infer the pattern**\n",
    "- üöÄ **Get consistent, formatted responses**\n",
    "\n",
    "### **When to Use Few-Shot?**\n",
    "- üìä **Data formatting** (converting between formats)\n",
    "- üé® **Style matching** (writing in specific tones)\n",
    "- üìè **Pattern recognition** (extracting information)\n",
    "- üîÑ **Task consistency** (ensuring uniform outputs)\n",
    "- üé≠ **Custom behaviors** (teaching new skills)\n",
    "- üîê **Domain-specific tasks** (industry jargon)\n",
    "\n",
    "### **The Science Behind It** üî¨\n",
    "Few-shot learning leverages **in-context learning** - the AI recognizes patterns from your examples and applies them to new inputs. It's like teaching a child by showing rather than explaining!\n",
    "\n",
    "### **Types of Few-Shot Learning:**\n",
    "1. **Zero-Shot**: No examples (just instructions)\n",
    "2. **One-Shot**: Single example\n",
    "3. **Few-Shot**: 2-5 examples (sweet spot!)\n",
    "4. **Many-Shot**: 5+ examples (diminishing returns)\n",
    "\n",
    "### **Pro Tips for Better Few-Shot:** üíé\n",
    "- ‚úÖ **Diverse examples**: Cover edge cases\n",
    "- ‚úÖ **Consistent format**: Keep structure uniform\n",
    "- ‚úÖ **Clear patterns**: Make the rule obvious\n",
    "- ‚úÖ **Quality > Quantity**: 3 perfect examples > 10 mediocre ones\n",
    "- ‚ùå **Avoid contradictions**: Don't confuse the model\n",
    "- ‚ùå **Don't over-example**: Too many can cause overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d058ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Few-Shot Learning - BULLETPROOF Solutions!\n",
      "\n",
      "============================================================\n",
      "METHOD 1: Testing ESCAPED BRACES version\n",
      "============================================================\n",
      "\n",
      "‚úÖ SUCCESS! Formatted prompt for: Sarah Johnson, 29 years old, works as a data scientist in Seattle\n",
      "--------------------------------------------------\n",
      "Extract information from text and format as JSON. Here are some examples:\n",
      "\n",
      "Input: John Smith, 28 years old, works as a software engineer in New York\n",
      "Output: {\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}\n",
      "\n",
      "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
      "Output: {\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}\n",
      "\n",
      "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
      "Output: {\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}\n",
      "\n",
      "Input: Sarah Johnson, 29 years old, works as a data scientist in Seattle\n",
      "Output:\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ SUCCESS! Formatted prompt for: Robert Brown, 51 years old, works as a CEO in Boston\n",
      "--------------------------------------------------\n",
      "Extract information from text and format as JSON. Here are some examples:\n",
      "\n",
      "Input: John Smith, 28 years old, works as a software engineer in New York\n",
      "Output: {\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}\n",
      "\n",
      "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
      "Output: {\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}\n",
      "\n",
      "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
      "Output: {\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}\n",
      "\n",
      "Input: Robert Brown, 51 years old, works as a CEO in Boston\n",
      "Output:\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "METHOD 2: Testing NO-TEMPLATE version\n",
      "============================================================\n",
      "\n",
      "‚úÖ SUCCESS! Manual prompt for: Sarah Johnson, 29 years old, works as a data scientist in Seattle\n",
      "--------------------------------------------------\n",
      "Extract information from text and format as JSON. Here are some examples:\n",
      "\n",
      "Input: John Smith, 28 years old, works as a software engineer in New York\n",
      "Output: {\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}\n",
      "\n",
      "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
      "Output: {\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}\n",
      "\n",
      "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
      "Output: {\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}\n",
      "\n",
      "Input: Sarah Johnson, 29 years old, works as a data scientist in Seattle\n",
      "Output:\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ SUCCESS! Manual prompt for: Robert Brown, 51 years old, works as a CEO in Boston\n",
      "--------------------------------------------------\n",
      "Extract information from text and format as JSON. Here are some examples:\n",
      "\n",
      "Input: John Smith, 28 years old, works as a software engineer in New York\n",
      "Output: {\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}\n",
      "\n",
      "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
      "Output: {\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}\n",
      "\n",
      "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
      "Output: {\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}\n",
      "\n",
      "Input: Robert Brown, 51 years old, works as a CEO in Boston\n",
      "Output:\n",
      "--------------------------------------------------\n",
      "\n",
      "üéâ BOTH methods work! Use whichever you prefer:\n",
      "‚Ä¢ Method 1: Standard LangChain with escaped braces\n",
      "‚Ä¢ Method 2: Manual string replacement (most reliable)\n",
      "\n",
      "üí° To use with LLM:\n",
      "# Method 1:\n",
      "# chain = LLMChain(llm=your_llm, prompt=few_shot_prompt_escaped)\n",
      "# response = chain.run(input='your test input')\n",
      "\n",
      "# Method 2:\n",
      "# final_prompt = template_with_json.replace('USER_INPUT_PLACEHOLDER', 'your test input')\n",
      "# response = your_llm.predict(final_prompt)\n"
     ]
    }
   ],
   "source": [
    "# üìä Few-Shot Example: Data Extraction and Formatting - BULLETPROOF VERSION\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# SOLUTION: Escape ALL curly braces by doubling them\n",
    "def create_bulletproof_prompt():\n",
    "    # Double all curly braces in the JSON examples to escape them\n",
    "    example_text = \"\"\"Extract information from text and format as JSON. Here are some examples:\n",
    "\n",
    "Input: John Smith, 28 years old, works as a software engineer in New York\n",
    "Output: {{\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}}\n",
    "\n",
    "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
    "Output: {{\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}}\n",
    "\n",
    "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
    "Output: {{\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}}\n",
    "\n",
    "Input: {input}\n",
    "Output:\"\"\"\n",
    "    \n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"input\"],\n",
    "        template=example_text\n",
    "    )\n",
    "\n",
    "# Alternative: Use string replacement to avoid template formatting entirely\n",
    "def create_no_template_prompt():\n",
    "    base_template = \"\"\"Extract information from text and format as JSON. Here are some examples:\n",
    "\n",
    "Input: John Smith, 28 years old, works as a software engineer in New York\n",
    "Output: JSON_PLACEHOLDER_1\n",
    "\n",
    "Input: Maria Garcia, 35 years old, works as a doctor in Los Angeles\n",
    "Output: JSON_PLACEHOLDER_2\n",
    "\n",
    "Input: David Lee, 42 years old, works as a teacher in Chicago\n",
    "Output: JSON_PLACEHOLDER_3\n",
    "\n",
    "Input: USER_INPUT_PLACEHOLDER\n",
    "Output:\"\"\"\n",
    "    \n",
    "    # Replace placeholders after template creation\n",
    "    json_examples = [\n",
    "        '{\"name\": \"John Smith\", \"age\": 28, \"occupation\": \"software engineer\", \"location\": \"New York\"}',\n",
    "        '{\"name\": \"Maria Garcia\", \"age\": 35, \"occupation\": \"doctor\", \"location\": \"Los Angeles\"}', \n",
    "        '{\"name\": \"David Lee\", \"age\": 42, \"occupation\": \"teacher\", \"location\": \"Chicago\"}'\n",
    "    ]\n",
    "    \n",
    "    # Replace JSON placeholders\n",
    "    for i, json_example in enumerate(json_examples, 1):\n",
    "        base_template = base_template.replace(f\"JSON_PLACEHOLDER_{i}\", json_example)\n",
    "    \n",
    "    return base_template\n",
    "\n",
    "# Method 1: Escaped braces version\n",
    "few_shot_prompt_escaped = create_bulletproof_prompt()\n",
    "\n",
    "# Method 2: Completely bypass template formatting\n",
    "template_with_json = create_no_template_prompt()\n",
    "\n",
    "print(\"üéØ Few-Shot Learning - BULLETPROOF Solutions!\\n\")\n",
    "\n",
    "# Test Method 1: Escaped braces\n",
    "print(\"=\"*60)\n",
    "print(\"METHOD 1: Testing ESCAPED BRACES version\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_inputs = [\n",
    "    \"Sarah Johnson, 29 years old, works as a data scientist in Seattle\",\n",
    "    \"Robert Brown, 51 years old, works as a CEO in Boston\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    for test_input in test_inputs:\n",
    "        formatted_prompt = few_shot_prompt_escaped.format(input=test_input)\n",
    "        print(f\"\\n‚úÖ SUCCESS! Formatted prompt for: {test_input}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(formatted_prompt)\n",
    "        print(\"-\" * 50)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Method 1 failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 2: Testing NO-TEMPLATE version\")  \n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method 2: Manual string replacement (guaranteed to work)\n",
    "for test_input in test_inputs:\n",
    "    final_prompt = template_with_json.replace(\"USER_INPUT_PLACEHOLDER\", test_input)\n",
    "    print(f\"\\n‚úÖ SUCCESS! Manual prompt for: {test_input}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(final_prompt)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüéâ BOTH methods work! Use whichever you prefer:\")\n",
    "print(\"‚Ä¢ Method 1: Standard LangChain with escaped braces\")\n",
    "print(\"‚Ä¢ Method 2: Manual string replacement (most reliable)\")\n",
    "\n",
    "print(\"\\nüí° To use with LLM:\")\n",
    "print(\"# Method 1:\")\n",
    "print(\"# chain = LLMChain(llm=your_llm, prompt=few_shot_prompt_escaped)\")\n",
    "print(\"# response = chain.run(input='your test input')\")\n",
    "print(\"\\n# Method 2:\")\n",
    "print(\"# final_prompt = template_with_json.replace('USER_INPUT_PLACEHOLDER', 'your test input')\")\n",
    "print(\"# response = your_llm.predict(final_prompt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "kslkdttvvt8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Style Transfer Magic!\n",
      "\n",
      "üìù Original: I want to loose fat\n",
      "üé® Newton Style: Original: I want to loose fat  \n",
      "Newton: I desire to diminish the corporeal adipose matter.\n",
      "\n",
      "----------------------------------------\n",
      "üìù Original: I want to loose fat\n",
      "üé® Tim Cook Style: Original: I want to lose fat  \n",
      "Tim Cook: At Apple, we believe in empowering individuals to achieve their health and wellness goals. It's about making informed choices and fostering a balanced lifestyle. Together, we can embrace a journey towards better well-being.\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# üé® Few-Shot Example 2: Creative Writing Style Transfer\n",
    "\n",
    "# Examples of different writing styles\n",
    "style_examples = [\n",
    "    {\n",
    "        \"style\": \"Shakespeare\",\n",
    "        \"input\": \"I love pizza\",\n",
    "        \"output\": \"Forsooth, mine heart doth yearn for yon circular feast, adorned with cheese most divine!\"\n",
    "    },\n",
    "    {\n",
    "        \"style\": \"Shakespeare\", \n",
    "        \"input\": \"The weather is nice\",\n",
    "        \"output\": \"Lo! The heavens smile upon us with gentle rays, and sweet zephyrs dance through verdant fields!\"\n",
    "    },\n",
    "    {\n",
    "        \"style\": \"Pirate\",\n",
    "        \"input\": \"I love pizza\",\n",
    "        \"output\": \"Arrr, me hearty! That round treasure o' cheese and sauce be callin' me name!\"\n",
    "    },\n",
    "    {\n",
    "        \"style\": \"Pirate\",\n",
    "        \"input\": \"The weather is nice\", \n",
    "        \"output\": \"Blimey! The sun be shinin' bright as doubloons, and the wind be perfect for sailin'!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dynamic few-shot prompt for style transfer\n",
    "def create_style_prompt(style, examples_list):\n",
    "    style_specific_examples = [ex for ex in examples_list if ex[\"style\"] == style]\n",
    "    \n",
    "    examples_text = \"\\n\\n\".join([\n",
    "        f\"Original: {ex['input']}\\n{style}: {ex['output']}\" \n",
    "        for ex in style_specific_examples\n",
    "    ])\n",
    "    \n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=f\"\"\"Transform the following text into {style} style.\n",
    "\n",
    "Examples:\n",
    "{examples_text}\n",
    "\n",
    "Now transform this:\n",
    "Original: {{text}}\n",
    "{style}:\"\"\"\n",
    "    )\n",
    "\n",
    "# Test different styles\n",
    "print(\"üé≠ Style Transfer Magic!\\n\")\n",
    "\n",
    "styles_to_test = [\"Newton\", \"Tim Cook\"]\n",
    "test_text = \"I want to loose fat\"\n",
    "\n",
    "for style in styles_to_test:\n",
    "    style_prompt = create_style_prompt(style, style_examples)\n",
    "    style_chain = LLMChain(llm=llm, prompt=style_prompt)\n",
    "    \n",
    "    result = style_chain.run(text=test_text)\n",
    "    print(f\"üìù Original: {test_text}\")\n",
    "    print(f\"üé® {style} Style: {result}\\n\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "o8m1nmdnb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ PATTERN RECOGNITION GAME!\n",
      "\n",
      "The AI will learn patterns from examples and apply them:\n",
      "\n",
      "üìö Training Examples:\n",
      "  ‚Ä¢ cat ‚Üí tac ‚Üí Pattern: Reverse the word\n",
      "  ‚Ä¢ hello ‚Üí HELLO ‚Üí Pattern: Convert to uppercase\n",
      "  ‚Ä¢ python ‚Üí p****n ‚Üí Pattern: Keep first and last letter, replace middle with asterisks\n",
      "\n",
      "üéØ Now let's test with new inputs!\n",
      "\n",
      "‚ùì world ‚Üí ?\n",
      "ü§ñ AI says: Based on the established patterns from the previous examples, for the word \"world\":\n",
      "\n",
      "1. Keep the first and last letters (w and d).\n",
      "2. Replace the middle letters (o, r, l) with asterisks.\n",
      "\n",
      "Following this pattern, the transformation for \"world\" would be:\n",
      "\n",
      "**Transformation: world ‚Üí w***d**\n",
      "\n",
      "‚ùì HELLO ‚Üí ?\n",
      "ü§ñ AI says: Transformation: HELLO ‚Üí *****  \n",
      "Pattern: Replace all letters with asterisks, maintaining the same number of characters.\n",
      "\n",
      "‚ùì coding ‚Üí ?\n",
      "ü§ñ AI says: To apply the identified pattern of keeping the first and last letter and replacing the middle letters with asterisks to the word \"coding\":\n",
      "\n",
      "1. Keep the first letter: c\n",
      "2. Keep the last letter: g\n",
      "3. Replace the middle letters (o, d, i, n) with asterisks: ****\n",
      "\n",
      "Therefore, the transformation for \"coding\" would be:\n",
      "\n",
      "**Transformation: coding ‚Üí c****g**\n",
      "\n",
      "‚ùì 98765 ‚Üí ?\n",
      "ü§ñ AI says: Based on the transformations provided, the pattern for the numerical input \"98765\" can be inferred as follows:\n",
      "\n",
      "- The transformation retains the first and last digit while replacing the middle digits with asterisks.\n",
      "\n",
      "Following this pattern:\n",
      "\n",
      "Transformation: 98765 ‚Üí 9***5\n",
      "\n",
      "So the final answer would be:\n",
      "**9***5**\n",
      "\n",
      "üí° FUN IMPLEMENTATION TIP:\n",
      "Create a 'teaching loop' where users can:\n",
      "1. Provide their own examples\n",
      "2. Test the AI's understanding\n",
      "3. Add more examples if needed\n",
      "4. Save successful patterns for reuse!\n"
     ]
    }
   ],
   "source": [
    "# üéÆ Few-Shot Example 3: Fun Pattern Recognition Games\n",
    "\n",
    "# Teaching AI to recognize and create patterns\n",
    "pattern_examples = [\n",
    "    {\n",
    "        \"input\": \"cat ‚Üí tac\",\n",
    "        \"output\": \"Reverse the word\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"hello ‚Üí HELLO\",\n",
    "        \"output\": \"Convert to uppercase\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"python ‚Üí p****n\",\n",
    "        \"output\": \"Keep first and last letter, replace middle with asterisks\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"12345 ‚Üí 1-2-3-4-5\",\n",
    "        \"output\": \"Add hyphens between each character\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a pattern recognition game\n",
    "print(\"üéÆ PATTERN RECOGNITION GAME!\\n\")\n",
    "print(\"The AI will learn patterns from examples and apply them:\\n\")\n",
    "\n",
    "# Show the examples\n",
    "print(\"üìö Training Examples:\")\n",
    "for ex in pattern_examples[:3]:  # Show only first 3\n",
    "    print(f\"  ‚Ä¢ {ex['input']} ‚Üí Pattern: {ex['output']}\")\n",
    "\n",
    "print(\"\\nüéØ Now let's test with new inputs!\\n\")\n",
    "\n",
    "# Create few-shot prompt for pattern recognition\n",
    "pattern_prompt = FewShotPromptTemplate(\n",
    "    examples=pattern_examples[:3],\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"input\", \"output\"],\n",
    "        template=\"Transformation: {input}\\nPattern: {output}\"\n",
    "    ),\n",
    "    prefix=\"Identify the transformation pattern from these examples:\",\n",
    "    suffix=\"Transformation: {test_input}\\nPattern:\",\n",
    "    input_variables=[\"test_input\"]\n",
    ")\n",
    "\n",
    "pattern_chain = LLMChain(llm=llm, prompt=pattern_prompt)\n",
    "\n",
    "# Test with new patterns\n",
    "test_patterns = [\n",
    "    \"world ‚Üí ?\",\n",
    "    \"HELLO ‚Üí ?\", \n",
    "    \"coding ‚Üí ?\",\n",
    "    \"98765 ‚Üí ?\"\n",
    "]\n",
    "\n",
    "for test in test_patterns:\n",
    "    result = pattern_chain.run(test_input=test)\n",
    "    print(f\"‚ùì {test}\")\n",
    "    print(f\"ü§ñ AI says: {result}\\n\")\n",
    "\n",
    "# Fun implementation tip\n",
    "print(\"üí° FUN IMPLEMENTATION TIP:\")\n",
    "print(\"Create a 'teaching loop' where users can:\")\n",
    "print(\"1. Provide their own examples\")\n",
    "print(\"2. Test the AI's understanding\")\n",
    "print(\"3. Add more examples if needed\")\n",
    "print(\"4. Save successful patterns for reuse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dwnps33buv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë®‚Äçüç≥ AI CHEF'S RECIPE GENERATOR!\n",
      "\n",
      "Give me ingredients, and I'll create a recipe!\n",
      "\n",
      "üõí Let's create some recipes:\n",
      "\n",
      "üì¶ Available ingredients: salmon, lemon, asparagus, butter\n",
      "\n",
      "üë®‚Äçüç≥ AI Chef suggests:\n",
      "**Lemon Butter Salmon with Asparagus**\n",
      "\n",
      "**Ingredients:**\n",
      "- 2 salmon fillets\n",
      "- 1 lemon (juiced and sliced)\n",
      "- 1 bunch asparagus (trimmed)\n",
      "- 2 tablespoons butter\n",
      "- Salt and pepper to taste\n",
      "\n",
      "**Steps:**\n",
      "1. Preheat a skillet over medium heat and melt 1 tablespoon of butter.\n",
      "2. Season the salmon fillets with salt and pepper, then place them skin-side down in the skillet.\n",
      "3. Cook the salmon for about 4-5 minutes until golden brown, then carefully flip and cook for another 4-5 minutes until cooked through.\n",
      "4. In the last 2 minutes of cooking, add the asparagus to the skillet alongside the salmon, and squeeze lemon juice over both.\n",
      "5. Add the remaining tablespoon of butter and lemon slices to the skillet, letting them melt and infuse the salmon and asparagus with flavor.\n",
      "6. Serve the salmon and asparagus warm, drizzled with the lemon butter sauce.\n",
      "\n",
      "**Time:** 20 minutes | **Serves:** 2\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "üí° PRACTICAL TIP: Few-Shot for Consistency\n",
      "When building production apps:\n",
      "‚Ä¢ Store successful examples in a database\n",
      "‚Ä¢ Let users rate outputs to build better examples\n",
      "‚Ä¢ Use domain expert examples for specialized tasks\n",
      "‚Ä¢ A/B test different example sets\n"
     ]
    }
   ],
   "source": [
    "# üçî Few-Shot Example 4: Recipe Generator from Ingredients\n",
    "\n",
    "# Teaching AI to create recipes from available ingredients\n",
    "recipe_examples = [\n",
    "    {\n",
    "        \"ingredients\": \"chicken, rice, soy sauce, garlic\",\n",
    "        \"recipe\": \"\"\"**Garlic Soy Chicken Rice Bowl**\n",
    "        1. Season chicken with salt and pepper\n",
    "        2. Saut√© minced garlic until fragrant\n",
    "        3. Cook chicken until golden (6-8 mins)\n",
    "        4. Add soy sauce and simmer\n",
    "        5. Serve over cooked rice\n",
    "        Time: 25 minutes | Serves: 2\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"pasta, tomatoes, basil, mozzarella\",\n",
    "        \"recipe\": \"\"\"**Caprese Pasta**\n",
    "        1. Cook pasta al dente\n",
    "        2. Dice tomatoes and mozzarella\n",
    "        3. Toss hot pasta with tomatoes\n",
    "        4. Add torn basil and mozzarella\n",
    "        5. Drizzle with olive oil\n",
    "        Time: 20 minutes | Serves: 3\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"ingredients\": \"eggs, spinach, cheese, mushrooms\",\n",
    "        \"recipe\": \"\"\"**Garden Veggie Omelet**\n",
    "        1. Saut√© mushrooms until golden\n",
    "        2. Wilt spinach in same pan\n",
    "        3. Beat eggs with salt and pepper\n",
    "        4. Pour eggs over veggies\n",
    "        5. Add cheese, fold omelet\n",
    "        Time: 15 minutes | Serves: 1\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create recipe generator with few-shot learning\n",
    "recipe_prompt = FewShotPromptTemplate(\n",
    "    examples=recipe_examples,\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"ingredients\", \"recipe\"],\n",
    "        template=\"Ingredients: {ingredients}\\n{recipe}\"\n",
    "    ),\n",
    "    prefix=\"Create a simple recipe from these ingredients. Include name, steps, time, and servings:\",\n",
    "    suffix=\"Ingredients: {user_ingredients}\\n\",\n",
    "    input_variables=[\"user_ingredients\"]\n",
    ")\n",
    "\n",
    "recipe_chain = LLMChain(llm=llm, prompt=recipe_prompt)\n",
    "\n",
    "print(\"üë®‚Äçüç≥ AI CHEF'S RECIPE GENERATOR!\\n\")\n",
    "print(\"Give me ingredients, and I'll create a recipe!\\n\")\n",
    "\n",
    "# Interactive recipe creation\n",
    "test_ingredients = [\n",
    "    \"salmon, lemon, asparagus, butter\",\n",
    "    \"potatoes, bacon, cheese, sour cream\",\n",
    "    \"tofu, broccoli, peanut butter, sesame oil\"\n",
    "]\n",
    "\n",
    "print(\"üõí Let's create some recipes:\\n\")\n",
    "for ingredients in test_ingredients[:1]:  # Test with first set\n",
    "    print(f\"üì¶ Available ingredients: {ingredients}\\n\")\n",
    "    recipe = recipe_chain.run(user_ingredients=ingredients)\n",
    "    print(f\"üë®‚Äçüç≥ AI Chef suggests:\\n{recipe}\\n\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nüí° PRACTICAL TIP: Few-Shot for Consistency\")\n",
    "print(\"When building production apps:\")\n",
    "print(\"‚Ä¢ Store successful examples in a database\")\n",
    "print(\"‚Ä¢ Let users rate outputs to build better examples\")\n",
    "print(\"‚Ä¢ Use domain expert examples for specialized tasks\")\n",
    "print(\"‚Ä¢ A/B test different example sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98554b91",
   "metadata": {},
   "source": [
    "## üé≠ Part 6: Role-Based Prompting - Transform AI into Any Expert!\n",
    "\n",
    "### **What is Role-Based Prompting?** \n",
    "Role-based prompting assigns a **specific persona** to the AI:\n",
    "- üë®‚Äçüè´ **Expert roles** (teacher, scientist, lawyer)\n",
    "- üé® **Creative roles** (poet, comedian, storyteller)\n",
    "- üíº **Professional roles** (consultant, analyst, coach)\n",
    "\n",
    "### **Why Use Roles?**\n",
    "- üéØ **Specialized knowledge** - Get domain-specific answers\n",
    "- üó£Ô∏è **Consistent tone** - Maintain character throughout\n",
    "- üìà **Better quality** - Role-focused responses are more accurate\n",
    "- üéÆ **Engagement** - Makes interactions more interesting!\n",
    "\n",
    "### **The Formula:** \"You are a [role] with [expertise]. Your task is to [objective].\" üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08cd2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Same Question, Different Experts!\n",
      "\n",
      "Question: Explain sigmoid function\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéì Data Scientist Response\n",
      "============================================================\n",
      "The sigmoid function is a mathematical function that maps any real-valued number into the range (0, 1). It is defined by the formula:\n",
      "\n",
      "\\[\n",
      "f(x) = \\frac{1}{1 + e^{-x}}\n",
      "\\]\n",
      "\n",
      "where \\( e \\) is the base of the natural logarithm, and \\( x \\) is the input to the function.\n",
      "\n",
      "### Key Properties of the Sigmoid Function:\n",
      "\n",
      "1. **Range**: The output of the sigmoid function is always between 0 and 1, making it particularly useful for models that predict probabilities.\n",
      "\n",
      "2. **S-shape**: The graph of the sigmoid function has an S-shaped curve, asymptotic to the lines \\( y = 0 \\) and \\( y = 1 \\). This characteristic allows it to smoothly transition between these two extremes.\n",
      "\n",
      "3. **Derivative**: The derivative of the sigmoid function can be expressed in terms of the function itself:\n",
      "   \\[\n",
      "   f'(x) = f(x)(1 - f(x))\n",
      "   \\]\n",
      "   This property is useful in optimization algorithms, such as gradient descent, as it simplifies the computation of gradients.\n",
      "\n",
      "4. **Monotonicity**: The sigmoid function is monotonically increasing, meaning that as \\( x \\) increases, \\( f(x) \\) also increases. This property is essential for its role in classification tasks, as it ensures a consistent interpretation of the output.\n",
      "\n",
      "### Applications:\n",
      "\n",
      "1. **Logistic Regression**: In logistic regression, the sigmoid function is used to model the probability that a given input belongs to a particular class. The output of the sigmoid function represents the probability, which can then be thresholded to make a classification decision.\n",
      "\n",
      "2. **Neural Networks**: The sigmoid function has historically been used as an activation function in neural networks, allowing neurons to output values between 0 and 1. However, it has largely been supplanted by other activation functions, such as ReLU, due to issues like vanishing gradients.\n",
      "\n",
      "3. **Biological Models**: The sigmoid function can also model growth processes, such as population growth and the spread of diseases, where the growth accelerates and then slows down as it approaches a carrying capacity.\n",
      "\n",
      "### Limitations:\n",
      "\n",
      "Despite its utility, the sigmoid function has some limitations. Notably, it can lead to vanishing gradient problems during training of deep networks, where gradients become very small, rendering weights unresponsive to updates. Additionally, it outputs values that are not centered around zero, which can hinder convergence in optimization algorithms.\n",
      "\n",
      "In summary, the sigmoid function is a fundamental mathematical construct that serves as a critical tool in various domains of data science, particularly in binary classification problems. Its properties and applications make it a staple in both statistical modeling and machine learning.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéì Business Strategist Response\n",
      "============================================================\n",
      "The sigmoid function is a mathematical function that has significant applications in various fields, particularly in statistics, machine learning, and business analytics. It is defined by the formula:\n",
      "\n",
      "\\[ S(x) = \\frac{1}{1 + e^{-x}} \\]\n",
      "\n",
      "Where:\n",
      "- \\( S(x) \\) is the output of the sigmoid function.\n",
      "- \\( e \\) is the base of the natural logarithm.\n",
      "- \\( x \\) is the input value.\n",
      "\n",
      "### Characteristics of the Sigmoid Function:\n",
      "\n",
      "1. **Output Range**: The function outputs values between 0 and 1, making it particularly useful for models that need to predict probabilities. For example, if you are assessing customer churn risk, a sigmoid output can help estimate the likelihood of a customer leaving.\n",
      "\n",
      "2. **S-shaped Curve**: The graph of the sigmoid function resembles an \"S\" shape. As \\( x \\) approaches negative infinity, the function approaches 0, and as \\( x \\) approaches positive infinity, it approaches 1. This characteristic allows the sigmoid to model scenarios where there are thresholds or limits to growth.\n",
      "\n",
      "3. **Gradient**: The function has a steeper gradient around the center (0) and flattens out as it approaches the asymptotes (0 and 1). This property can be leveraged in optimization problems, as it allows for effective backpropagation in neural networks by providing a gradient that can be used to update weights.\n",
      "\n",
      "### Applications in Business Strategy:\n",
      "\n",
      "1. **Market Segmentation**: The sigmoid function can help in classifying customers based on their likelihood to respond to marketing initiatives. By modeling customer data with a sigmoid function, businesses can identify high-potential segments for targeted campaigns.\n",
      "\n",
      "2. **Sales Forecasting**: In sales models, the sigmoid function can be used to predict conversion rates based on various input metrics (e.g., lead quality, engagement levels), enabling companies to allocate resources effectively for maximum ROI.\n",
      "\n",
      "3. **Risk Assessment**: In financial modeling, the sigmoid function can help assess the probability of default or other risk metrics, allowing businesses to make informed decisions regarding credit and investment strategies.\n",
      "\n",
      "### Actionable Recommendations:\n",
      "\n",
      "- **Utilize Sigmoid Functions in Predictive Models**: Incorporate the sigmoid function in your predictive analytics toolkit to enhance the accuracy of models relating to customer behavior and market trends.\n",
      "\n",
      "- **Optimize Marketing Strategies**: Use the insights gained from sigmoid-based models to tailor your marketing strategies, ensuring that you focus efforts on high-probability customers for better conversion rates.\n",
      "\n",
      "- **Monitor Performance Metrics**: Regularly assess the effectiveness of the models using the sigmoid function and adjust parameters based on real-world outcomes to improve predictive accuracy over time.\n",
      "\n",
      "By leveraging the properties of the sigmoid function within your business strategy, you can derive actionable insights that drive growth, improve customer engagement, and ultimately enhance your bottom line.\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "üéì Therapist Response\n",
      "============================================================\n",
      "It seems like you‚Äôre seeking information about the sigmoid function, which is a mathematical concept often used in fields like statistics, machine learning, and biology. While this isn‚Äôt my primary area of expertise, I can certainly help you understand it in a straightforward way.\n",
      "\n",
      "The sigmoid function is a type of mathematical curve that has an \"S\" shape. It‚Äôs defined by the formula:\n",
      "\n",
      "\\[ S(x) = \\frac{1}{1 + e^{-x}} \\]\n",
      "\n",
      "Here, \\( e \\) is the base of the natural logarithm, and \\( x \\) is the input to the function. The output of the sigmoid function always ranges between 0 and 1, which makes it particularly useful for models that need to predict probabilities.\n",
      "\n",
      "### Key Characteristics of the Sigmoid Function:\n",
      "\n",
      "1. **Output Range**: The function outputs values between 0 and 1. This is valuable in contexts like binary classification, where you want to represent probabilities.\n",
      "\n",
      "2. **S-Shape**: The curve starts near 0 when \\( x \\) is very negative, rises steeply around \\( x = 0 \\), and asymptotically approaches 1 as \\( x \\) becomes very positive.\n",
      "\n",
      "3. **Gradient**: The slope of the sigmoid function is steepest at \\( x = 0 \\). This means small changes in \\( x \\) around this point can lead to significant changes in the output, which is useful in optimization processes.\n",
      "\n",
      "4. **Applications**: It's widely used in logistic regression, neural networks, and modeling growth processes.\n",
      "\n",
      "If you're exploring the sigmoid function in relation to a specific application or if it relates to your personal or professional growth, feel free to share. Sometimes, understanding the underlying concepts can help us approach our challenges or goals with clearer insights.\n",
      "============================================================\n",
      "\n",
      "üí° Notice how each expert approaches the same problem differently!\n"
     ]
    }
   ],
   "source": [
    "# üéì Role-Based Example 1: Expert Consultation System\n",
    "\n",
    "# Define different expert roles\n",
    "expert_roles = {\n",
    "    \"Data Scientist\": {\n",
    "        \"expertise\": \"statistical analysis, machine learning, and data visualization\",\n",
    "        \"style\": \"analytical and precise, using technical terms when appropriate\",\n",
    "        \"approach\": \"data-driven insights and evidence-based recommendations\"\n",
    "    },\n",
    "    \"Business Strategist\": {\n",
    "        \"expertise\": \"market analysis, competitive positioning, and growth strategies\",\n",
    "        \"style\": \"strategic and results-oriented, focusing on ROI and business impact\",\n",
    "        \"approach\": \"SWOT analysis, market trends, and actionable business recommendations\"\n",
    "    },\n",
    "    \"Therapist\": {\n",
    "        \"expertise\": \"emotional well-being, stress management, and personal growth\",\n",
    "        \"style\": \"empathetic and supportive, using active listening techniques\",\n",
    "        \"approach\": \"cognitive-behavioral strategies and mindfulness techniques\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_expert_prompt(role, role_info):\n",
    "    return PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=f\"\"\"You are an expert {role} with deep expertise in {role_info['expertise']}.\n",
    "\n",
    "Your communication style is {role_info['style']}.\n",
    "Your approach involves {role_info['approach']}.\n",
    "\n",
    "User Question: {{question}}\n",
    "\n",
    "Please provide your expert response:\"\"\"\n",
    "    )\n",
    "\n",
    "# Test with different experts\n",
    "question = \"Explain sigmoid function\"\n",
    "print(\"üéØ Same Question, Different Experts!\\n\")\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for role, info in expert_roles.items():\n",
    "    expert_prompt = create_expert_prompt(role, info)\n",
    "    expert_chain = LLMChain(llm=llm, prompt=expert_prompt)\n",
    "    \n",
    "    response = expert_chain.run(question=question)\n",
    "    pretty_print(f\"üéì {role} Response\", response, Fore.CYAN)\n",
    "    \n",
    "print(Fore.YELLOW + \"üí° Notice how each expert approaches the same problem differently!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wss2z0sgkv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ Chat with Famous Characters!\n",
      "\n",
      "Available characters:\n",
      "1. Sherlock Holmes\n",
      "2. Yoda\n",
      "3. Gordon Ramsay\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose a character (1-3, or press Enter for default):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ You're now chatting with Sherlock Holmes!\n",
      "üí° Have a 3-message conversation (or type 'exit' to end)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (message 1/3):  yo sherlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Holmes: Ah, a rather casual greeting, I must say. \"Yo\" is hardly an expression befitting the gravity of our circumstances, yet I shall indulge you. What brings you to my doorstep today? Surely, you haven't come merely to exchange pleasantries. I find myself in need of a stimulating case to occupy my mind. Speak, and let us see if your dilemma can pique my interest.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You (message 2/3):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Holmes: Farewell!\n"
     ]
    }
   ],
   "source": [
    "# üéÆ Role-Based Example 2: Interactive Character AI\n",
    "\n",
    "# Create a character with personality and backstory\n",
    "character_prompt = PromptTemplate(\n",
    "    input_variables=[\"character_name\", \"personality\", \"backstory\", \"user_input\"],\n",
    "    template=\"\"\"You are {character_name}, a character with the following traits:\n",
    "\n",
    "Personality: {personality}\n",
    "Backstory: {backstory}\n",
    "\n",
    "Stay in character at all times. Respond naturally as this character would.\n",
    "\n",
    "User says: {user_input}\n",
    "\n",
    "Your response (as {character_name}):\"\"\"\n",
    ")\n",
    "\n",
    "# Define some fun characters\n",
    "characters = {\n",
    "    \"Sherlock Holmes\": {\n",
    "        \"personality\": \"Brilliant, observant, logical, slightly arrogant, easily bored\",\n",
    "        \"backstory\": \"World's greatest detective, lives at 221B Baker Street, solves impossible cases\"\n",
    "    },\n",
    "    \"Yoda\": {\n",
    "        \"personality\": \"Wise, patient, speaks in unique syntax, philosophical\",\n",
    "        \"backstory\": \"900-year-old Jedi Master, trained countless Jedi, strong in the Force\"\n",
    "    },\n",
    "    \"Gordon Ramsay\": {\n",
    "        \"personality\": \"Passionate about cooking, perfectionist, brutally honest, caring underneath\",\n",
    "        \"backstory\": \"World-renowned chef, multiple Michelin stars, hosts cooking shows\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Interactive character conversation (limited to 3 exchanges to avoid infinite loops)\n",
    "print(\"üéÆ Chat with Famous Characters!\\n\")\n",
    "print(\"Available characters:\")\n",
    "for i, char in enumerate(characters.keys(), 1):\n",
    "    print(f\"{i}. {char}\")\n",
    "\n",
    "char_choice = safe_input(\"\\nChoose a character (1-3, or press Enter for default): \", \"1\")\n",
    "try:\n",
    "    char_index = int(char_choice) - 1 if char_choice.isdigit() else 0\n",
    "    char_index = max(0, min(2, char_index))  # Ensure valid range\n",
    "    char_name = list(characters.keys())[char_index]\n",
    "except:\n",
    "    char_name = \"Sherlock Holmes\"\n",
    "\n",
    "char_info = characters[char_name]\n",
    "\n",
    "try:\n",
    "    character_chain = LLMChain(llm=llm, prompt=character_prompt)\n",
    "    \n",
    "    print(f\"\\nüé≠ You're now chatting with {char_name}!\")\n",
    "    print(\"üí° Have a 3-message conversation (or type 'exit' to end)\\n\")\n",
    "    \n",
    "    # Limit to 3 exchanges to prevent infinite loops in notebook\n",
    "    max_exchanges = 3\n",
    "    for exchange in range(max_exchanges):\n",
    "        user_input = safe_input(f\"You (message {exchange+1}/{max_exchanges}): \")\n",
    "        \n",
    "        if user_input.lower() == 'exit' or not user_input:\n",
    "            print(f\"{char_name}: Farewell!\")\n",
    "            break\n",
    "        \n",
    "        response = character_chain.run(\n",
    "            character_name=char_name,\n",
    "            personality=char_info[\"personality\"],\n",
    "            backstory=char_info[\"backstory\"],\n",
    "            user_input=user_input\n",
    "        )\n",
    "        print(f\"{char_name}: {response}\\n\")\n",
    "    \n",
    "    if exchange == max_exchanges - 1:\n",
    "        print(f\"\\nüé¨ Scene ended! {char_name} takes a bow.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error in character interaction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "m29s0hb90ij",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ DYNAMIC ROLE-PLAYING SYSTEM\n",
      "\n",
      "Mix and match personality traits to create unique AI personas!\n",
      "\n",
      "üìö Task: Explain what recursion is in programming\n",
      "\n",
      "Watch how different personality traits affect the explanation:\n",
      "\n",
      "Teacher 1: a casual formality, enthusiastic emotion, beginner-friendly expertise programming teacher\n",
      "----------------------------------------\n",
      "Hey there, programming explorer! üåü Let's dive into the fascinating world of recursion‚Äîit's like a little adventure in code!\n",
      "\n",
      "So, what is recursion? Think of it as a way of solving problems where a function calls itself to work on smaller pieces of the same problem. Imagine you‚Äôre trying to climb a s...\n",
      "\n",
      "Teacher 2: a academic formality, neutral emotion, expert-level expertise programming teacher\n",
      "----------------------------------------\n",
      "Recursion is a fundamental programming concept characterized by a function calling itself in order to solve a problem. This technique is particularly useful for problems that can be broken down into smaller, similar subproblems. The recursive function typically consists of two primary components: th...\n",
      "\n",
      "üí° IMPLEMENTATION TIP: Dynamic Roles\n",
      "Build a role configuration system where you can:\n",
      "‚Ä¢ Save successful role combinations\n",
      "‚Ä¢ Let users create custom personas\n",
      "‚Ä¢ Auto-select roles based on task type\n",
      "‚Ä¢ Combine multiple roles for team simulations!\n"
     ]
    }
   ],
   "source": [
    "# üé≤ Role-Based Example 3: The Ultimate Role-Playing System\n",
    "\n",
    "# Create a dynamic role system with personality traits\n",
    "class DynamicRoleSystem:\n",
    "    \"\"\"Advanced role-based prompting with personality dimensions\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.personality_dimensions = {\n",
    "            \"formality\": [\"casual\", \"professional\", \"academic\"],\n",
    "            \"emotion\": [\"neutral\", \"enthusiastic\", \"empathetic\"],\n",
    "            \"expertise\": [\"beginner-friendly\", \"intermediate\", \"expert-level\"],\n",
    "            \"verbosity\": [\"concise\", \"balanced\", \"detailed\"]\n",
    "        }\n",
    "    \n",
    "    def create_role(self, base_role, personality_mix):\n",
    "        \"\"\"Create a nuanced role with personality traits\"\"\"\n",
    "        traits = []\n",
    "        for dimension, level in personality_mix.items():\n",
    "            if dimension in self.personality_dimensions:\n",
    "                traits.append(f\"{level} {dimension}\")\n",
    "        \n",
    "        return f\"a {', '.join(traits)} {base_role}\"\n",
    "    \n",
    "    def generate_response(self, role_desc, task):\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"role\", \"task\"],\n",
    "            template=\"\"\"You are {role}.\n",
    "            \n",
    "Your unique traits shape how you communicate and solve problems.\n",
    "Maintain these characteristics throughout your response.\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Response (in character):\"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        return chain.run(role=role_desc, task=task)\n",
    "\n",
    "# Initialize the system\n",
    "role_system = DynamicRoleSystem(llm)\n",
    "\n",
    "print(\"üé≤ DYNAMIC ROLE-PLAYING SYSTEM\\n\")\n",
    "print(\"Mix and match personality traits to create unique AI personas!\\n\")\n",
    "\n",
    "\n",
    "# Example: Create different teachers\n",
    "teaching_task = \"Explain what recursion is in programming\"\n",
    "\n",
    "roles_to_test = [\n",
    "    {\n",
    "        \"base\": \"programming teacher\",\n",
    "        \"traits\": {\"formality\": \"casual\", \"emotion\": \"enthusiastic\", \"expertise\": \"beginner-friendly\"}\n",
    "    },\n",
    "    {\n",
    "        \"base\": \"programming teacher\", \n",
    "        \"traits\": {\"formality\": \"academic\", \"emotion\": \"neutral\", \"expertise\": \"expert-level\"}\n",
    "    },\n",
    "    {\n",
    "        \"base\": \"programming teacher\",\n",
    "        \"traits\": {\"formality\": \"professional\", \"emotion\": \"empathetic\", \"expertise\": \"intermediate\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìö Task: {teaching_task}\\n\")\n",
    "print(\"Watch how different personality traits affect the explanation:\\n\")\n",
    "\n",
    "for i, role_config in enumerate(roles_to_test[:2], 1):  # Test first 2\n",
    "    role_desc = role_system.create_role(role_config[\"base\"], role_config[\"traits\"])\n",
    "    print(f\"Teacher {i}: {role_desc}\")\n",
    "    print(\"-\" * 40)\n",
    "    response = role_system.generate_response(role_desc, teaching_task)\n",
    "    print(response[:300] + \"...\\n\")  # Show first 300 chars\n",
    "\n",
    "print(\"üí° IMPLEMENTATION TIP: Dynamic Roles\")\n",
    "print(\"Build a role configuration system where you can:\")\n",
    "print(\"‚Ä¢ Save successful role combinations\")\n",
    "print(\"‚Ä¢ Let users create custom personas\")\n",
    "print(\"‚Ä¢ Auto-select roles based on task type\")\n",
    "print(\"‚Ä¢ Combine multiple roles for team simulations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c6a71",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 7: Building Robust Prompt Templates\n",
    "\n",
    "### **What Makes a Template Robust?** üí™\n",
    "- **Modular**: Reusable components\n",
    "- **Flexible**: Adapts to different inputs\n",
    "- **Validated**: Handles edge cases\n",
    "- **Maintainable**: Easy to update\n",
    "- **Scalable**: Works at production scale\n",
    "\n",
    "### **Best Practices:**\n",
    "1. **Use clear variable names** `{user_query}` not `{q}`\n",
    "2. **Add input validation** - Check for required fields\n",
    "3. **Include error handling** - Graceful failures\n",
    "4. **Version your prompts** - Track changes over time\n",
    "5. **Test edge cases** - Empty inputs, long texts, special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f403ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Testing with VALID inputs:\n",
      "\n",
      "You are a professional customer service representative for TechCorp Solutions.\n",
      "\n",
      "Customer Information:\n",
      "- Name: Sarah Johnson\n",
      "- Account Type: Premium\n",
      "- Previous Interactions: Not specified\n",
      "\n",
      "Customer Query: My subscription isn't working\n",
      "\n",
      "Guidelines:\n",
      "1. Be polite and professional\n",
      "2. Address the customer by name\n",
      "3. Reference their account type when relevant\n",
      "4. Provide clear, actionable solutions\n",
      "5. Ask if they need further assistance\n",
      "\n",
      "Response:\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚ùå Testing with MISSING required input:\n",
      "\n",
      "Error in prompt template: Missing required variable: customer_name\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìä Template Statistics:\n",
      "{\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"usage_count\": 1,\n",
      "  \"required_vars\": [\n",
      "    \"company_name\",\n",
      "    \"customer_name\",\n",
      "    \"query\"\n",
      "  ],\n",
      "  \"optional_vars\": [\n",
      "    \"account_type\",\n",
      "    \"interaction_history\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# üèóÔ∏è Building a Production-Ready Prompt Template System\n",
    "\n",
    "class RobustPromptTemplate:\n",
    "    \"\"\"A production-ready prompt template with validation and error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, template: str, required_vars: List[str], optional_vars: List[str] = None):\n",
    "        self.template = template\n",
    "        self.required_vars = required_vars\n",
    "        self.optional_vars = optional_vars or []\n",
    "        self.version = \"1.0.0\"\n",
    "        self.usage_count = 0\n",
    "        \n",
    "    def validate_inputs(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Validate and sanitize inputs\"\"\"\n",
    "        validated = {}\n",
    "        \n",
    "        # Check required variables\n",
    "        for var in self.required_vars:\n",
    "            if var not in inputs:\n",
    "                raise ValueError(f\"Missing required variable: {var}\")\n",
    "            \n",
    "            # Sanitize input\n",
    "            value = inputs[var]\n",
    "            if value is None or (isinstance(value, str) and not value.strip()):\n",
    "                raise ValueError(f\"Variable '{var}' cannot be empty\")\n",
    "            \n",
    "            validated[var] = value\n",
    "        \n",
    "        # Handle optional variables\n",
    "        for var in self.optional_vars:\n",
    "            validated[var] = inputs.get(var, \"Not specified\")\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        \"\"\"Format the template with validation\"\"\"\n",
    "        try:\n",
    "            validated_inputs = self.validate_inputs(kwargs)\n",
    "            self.usage_count += 1\n",
    "            return self.template.format(**validated_inputs)\n",
    "        except Exception as e:\n",
    "            return f\"Error in prompt template: {str(e)}\"\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get template usage statistics\"\"\"\n",
    "        return {\n",
    "            \"version\": self.version,\n",
    "            \"usage_count\": self.usage_count,\n",
    "            \"required_vars\": self.required_vars,\n",
    "            \"optional_vars\": self.optional_vars\n",
    "        }\n",
    "\n",
    "# Example: Building a robust customer service bot template\n",
    "customer_service_template = RobustPromptTemplate(\n",
    "    template=\"\"\"You are a professional customer service representative for {company_name}.\n",
    "\n",
    "Customer Information:\n",
    "- Name: {customer_name}\n",
    "- Account Type: {account_type}\n",
    "- Previous Interactions: {interaction_history}\n",
    "\n",
    "Customer Query: {query}\n",
    "\n",
    "Guidelines:\n",
    "1. Be polite and professional\n",
    "2. Address the customer by name\n",
    "3. Reference their account type when relevant\n",
    "4. Provide clear, actionable solutions\n",
    "5. Ask if they need further assistance\n",
    "\n",
    "Response:\"\"\",\n",
    "    required_vars=[\"company_name\", \"customer_name\", \"query\"],\n",
    "    optional_vars=[\"account_type\", \"interaction_history\"]\n",
    ")\n",
    "\n",
    "# Test with valid inputs\n",
    "print(\"‚úÖ Testing with VALID inputs:\\n\")\n",
    "valid_response = customer_service_template.format(\n",
    "    company_name=\"TechCorp Solutions\",\n",
    "    customer_name=\"Sarah Johnson\",\n",
    "    query=\"My subscription isn't working\",\n",
    "    account_type=\"Premium\"\n",
    ")\n",
    "print(valid_response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test with missing required input\n",
    "print(\"‚ùå Testing with MISSING required input:\\n\")\n",
    "error_response = customer_service_template.format(\n",
    "    company_name=\"TechCorp Solutions\",\n",
    "    query=\"Help needed\"\n",
    "    # Missing customer_name!\n",
    ")\n",
    "print(error_response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Show template statistics\n",
    "print(\"üìä Template Statistics:\")\n",
    "print(json.dumps(customer_service_template.get_stats(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "m934row7dv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Adaptive Prompt System Demo\n",
      "\n",
      "üìù Input: Analyze the trend in these sales numbers: 100, 150, 140, 180, 220\n",
      "   Task Type: analytical | Complexity: high\n",
      "\n",
      "ü§ñ Response:\n",
      "To analyze the trend in the provided sales numbers (100, 150, 140, 180, 220), we will follow the outlined steps.\n",
      "\n",
      "### Step 1: Understand the Requirements\n",
      "We need to identify the trend in the sales numbers over the given time period. This involves looking for patterns, changes, or any significant insights that can be derived from the data.\n",
      "\n",
      "### Step 2: Break Down the Problem\n",
      "1. **Data Overview**: We have a sequence of sales numbers that represent sales over a period.\n",
      "2. **Identify Trend Type**: We are looking for an upward or downward trend, seasonality, or cyclical patterns.\n",
      "3. **Calculate Growth Rates**: This can help us understand how sales are changing over time.\n",
      "4. **Visual Representation**: Creating a visual representation (like a line graph) can help in observing trends more clearly.\n",
      "\n",
      "### Step 3: Apply Relevant Concepts\n",
      "1. **Calculate Changes**:\n",
      "   - From 100 to 150: Increase of 50\n",
      "   - From 150 to 140: Decrease of 10\n",
      "   - From 140 to 180: Increase of 40\n",
      "   - From 180 to 220: Increase of 40\n",
      "\n",
      "2. **Calculate Growth Rates**:\n",
      "   - Growth from 100 to 150: \\((150 - 100) / 100 = 0.5\\) or 50%\n",
      "   - Growth from 150 to 140: \\((140 - 150) / 150 = -0.0667\\) or -6.67%\n",
      "   - Growth from 140 to 180: \\((180 - 140) / 140 = 0.2857\\) or 28.57%\n",
      "   - Growth from 180 to 220: \\((220 - 180) / 180 = 0.2222\\) or 22.22%\n",
      "\n",
      "3. **Overall Trend**: \n",
      "   - The first increase (50%) indicates a strong initial growth.\n",
      "   - The second change shows a slight decline (-6.67%), which could indicate a temporary setback.\n",
      "   - The subsequent increases (28.57% and 22.22%) suggest a recovery and continued growth.\n",
      "\n",
      "### Step 4: Synthesize the Solution\n",
      "- **Trend Summary**: The sales numbers show an initial strong growth, followed by a small decline, and then a robust recovery with consistent growth in the final two periods. \n",
      "- **Interpretation**: Overall, the trend appears to be positive despite a minor dip. The sales figures indicate a generally upward trajectory, suggesting that the business is likely on a growth path, and any setbacks may be short-lived.\n",
      "- **Recommendation**: It may be beneficial to investigate the reasons behind the dip from 150 to 140 to ensure strategies are in place to maintain growth and address potential issues that caused the decline.\n",
      "\n",
      "### Visualization (Optional)\n",
      "If this were a visual analysis, a line graph depicting the sales numbers over time would clearly demonstrate the upward trend with the small dip, making it easier to communicate insights visually.\n",
      "\n",
      "In conclusion, the sales trend analysis indicates positive growth with a need for further investigation into short-term declines to ensure sustained upward momentum.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Input: Write a haiku about programming\n",
      "   Task Type: creative | Complexity: low\n",
      "\n",
      "ü§ñ Response:\n",
      "Lines of code converge,  \n",
      "Logic dances in the dark,  \n",
      "Dreams in bits emerge.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Input: Explain how a REST API works\n",
      "   Task Type: technical | Complexity: medium\n",
      "\n",
      "ü§ñ Response:\n",
      "Certainly! A REST (Representational State Transfer) API is an architectural style used for designing networked applications. It leverages standard HTTP protocols to enable communication between a client and a server. Here‚Äôs a structured explanation of how a REST API works, covering key aspects:\n",
      "\n",
      "### 1. **Core Principles of REST**\n",
      "   - **Statelessness**: Each API request from the client to the server must contain all the information the server needs to fulfill that request. The server does not store any client context between requests, making each interaction independent.\n",
      "   - **Client-Server Architecture**: The client and server are separate entities that communicate over a network. This separation allows for the development of client and server components independently.\n",
      "   - **Uniform Interface**: REST APIs use a uniform set of conventions for interacting with resources, which simplifies and decouples the architecture. This includes standardized methods (GET, POST, PUT, DELETE) and resource URIs (Uniform Resource Identifiers).\n",
      "   - **Resource-Based**: REST APIs focus on resources (data entities) that are identified by URIs. Clients interact with these resources using standard HTTP methods.\n",
      "\n",
      "### 2. **HTTP Methods and Their Usage**\n",
      "   - **GET**: Retrieve data from the server. It is safe and idempotent, meaning it can be called multiple times without changing the resource's state.\n",
      "   - **POST**: Create a new resource on the server. It is not idempotent as it can result in different states with each call.\n",
      "   - **PUT**: Update an existing resource or create it if it does not exist. It is idempotent, meaning multiple identical requests will result in the same state.\n",
      "   - **DELETE**: Remove a resource from the server. It is idempotent as repeated calls will not further affect the state after the resource is deleted.\n",
      "\n",
      "### 3. **Resource Representation**\n",
      "   - Resources can be represented in various formats, such as JSON, XML, or HTML. JSON is the most commonly used format due to its lightweight nature and ease of use with JavaScript.\n",
      "   - The server responds to client requests with a representation of the resource, usually including metadata (like HTTP status codes) and the resource's current state.\n",
      "\n",
      "### 4. **Stateless Communication**\n",
      "   - Each request must include all necessary context (e.g., authentication tokens, request parameters). This ensures that servers do not need to maintain session information, allowing for easier scalability and reliability.\n",
      "   - The use of tokens (e.g., JWT - JSON Web Tokens) is common for managing authentication and authorization in stateless interactions.\n",
      "\n",
      "### 5. **HTTP Status Codes**\n",
      "   - REST APIs utilize standard HTTP status codes to indicate the result of an API call:\n",
      "     - **200 OK**: Successful GET or PUT request.\n",
      "     - **201 Created**: Successful POST request that creates a resource.\n",
      "     - **204 No Content**: Successful DELETE request.\n",
      "     - **400 Bad Request**: Client error, often due to invalid input.\n",
      "     - **401 Unauthorized**: Authentication is required and has failed or not been provided.\n",
      "     - **404 Not Found**: The requested resource does not exist.\n",
      "     - **500 Internal Server Error**: An error occurred on the server.\n",
      "\n",
      "### 6. **HATEOAS (Hypermedia as the Engine of Application State)**\n",
      "   - A constraint of REST that allows clients to interact with the application entirely through hypermedia links provided dynamically by the server. Clients can discover actions they can perform on resources by navigating links in the responses.\n",
      "\n",
      "### 7. **Versioning**\n",
      "   - REST APIs may need to evolve over time. Versioning can be implemented in various ways, such as through URL paths (e.g., `/api/v1/resource`) or HTTP headers, to ensure backward compatibility with existing clients.\n",
      "\n",
      "### Conclusion\n",
      "In summary, a REST API is a powerful and widely adopted method for enabling communication between clients and servers over the web. By adhering to its principles and utilizing standard HTTP methods, REST APIs promote scalability, simplicity, and a clear separation of concerns in software architectures.\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üîÑ Advanced Template Composition - Combining Multiple Techniques\n",
    "\n",
    "class ComposablePromptSystem:\n",
    "    \"\"\"Combine CoT, Few-Shot, and Role-based prompting in one system\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.templates = {}\n",
    "        \n",
    "    def add_template(self, name: str, template: PromptTemplate):\n",
    "        \"\"\"Add a reusable template\"\"\"\n",
    "        self.templates[name] = template\n",
    "        \n",
    "    def compose(self, components: List[str]) -> str:\n",
    "        \"\"\"Compose multiple prompt techniques\"\"\"\n",
    "        composed = []\n",
    "        for component in components:\n",
    "            if component in self.templates:\n",
    "                composed.append(self.templates[component].template)\n",
    "        return \"\\n\\n\".join(composed)\n",
    "    \n",
    "    def create_adaptive_prompt(self, task_type: str, complexity: str) -> PromptTemplate:\n",
    "        \"\"\"Create an adaptive prompt based on task requirements\"\"\"\n",
    "        \n",
    "        base_components = []\n",
    "        \n",
    "        # Add role based on task\n",
    "        if task_type == \"analytical\":\n",
    "            base_components.append(\"You are a data analyst with expertise in statistics and insights.\")\n",
    "        elif task_type == \"creative\":\n",
    "            base_components.append(\"You are a creative writer with imagination and flair.\")\n",
    "        elif task_type == \"technical\":\n",
    "            base_components.append(\"You are a software engineer with deep technical knowledge.\")\n",
    "        \n",
    "        # Add technique based on complexity\n",
    "        if complexity == \"high\":\n",
    "            base_components.append(\"Let's think through this step by step:\")\n",
    "            base_components.append(\"1. Understand the requirements\")\n",
    "            base_components.append(\"2. Break down the problem\")\n",
    "            base_components.append(\"3. Apply relevant concepts\")\n",
    "            base_components.append(\"4. Synthesize the solution\")\n",
    "        elif complexity == \"medium\":\n",
    "            base_components.append(\"Consider the key aspects and provide a structured response.\")\n",
    "        else:\n",
    "            base_components.append(\"Provide a clear and concise answer.\")\n",
    "        \n",
    "        base_components.append(\"\\nUser Input: {input}\\n\\nResponse:\")\n",
    "        \n",
    "        return PromptTemplate(\n",
    "            input_variables=[\"input\"],\n",
    "            template=\"\\n\".join(base_components)\n",
    "        )\n",
    "\n",
    "# Create the composable system\n",
    "prompt_system = ComposablePromptSystem(llm)\n",
    "\n",
    "# Test adaptive prompting\n",
    "print(\"üéØ Adaptive Prompt System Demo\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"input\": \"Analyze the trend in these sales numbers: 100, 150, 140, 180, 220\",\n",
    "        \"task_type\": \"analytical\",\n",
    "        \"complexity\": \"high\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Write a haiku about programming\",\n",
    "        \"task_type\": \"creative\",\n",
    "        \"complexity\": \"low\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Explain how a REST API works\",\n",
    "        \"task_type\": \"technical\",\n",
    "        \"complexity\": \"medium\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    print(f\"üìù Input: {test['input']}\")\n",
    "    print(f\"   Task Type: {test['task_type']} | Complexity: {test['complexity']}\\n\")\n",
    "    \n",
    "    # Create adaptive prompt\n",
    "    adaptive_prompt = prompt_system.create_adaptive_prompt(\n",
    "        test[\"task_type\"], \n",
    "        test[\"complexity\"]\n",
    "    )\n",
    "    \n",
    "    # Execute with LangChain\n",
    "    chain = LLMChain(llm=llm, prompt=adaptive_prompt)\n",
    "    response = chain.run(input=test[\"input\"])\n",
    "    \n",
    "    print(f\"ü§ñ Response:\\n{response}\\n\")\n",
    "    print(\"-\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fae48f",
   "metadata": {},
   "source": [
    "## üêõ Part 8: Debugging Common Prompt Failures\n",
    "\n",
    "### **Top 5 Prompt Failures and How to Fix Them** üîß\n",
    "\n",
    "1. **üéØ Ambiguous Instructions** ‚Üí Be specific!\n",
    "2. **üìè Inconsistent Output Format** ‚Üí Use few-shot examples\n",
    "3. **üåä Context Overflow** ‚Üí Summarize or chunk\n",
    "4. **üé≠ Persona Drift** ‚Üí Reinforce role regularly\n",
    "5. **‚ùå Hallucinations** ‚Üí Add fact-checking steps\n",
    "\n",
    "### **Debugging Toolkit:**\n",
    "- üîç **Prompt Analyzer** - Identify weak points\n",
    "- üìä **Response Validator** - Check output quality\n",
    "- üîÑ **Iterative Refinement** - Test and improve\n",
    "- üìà **Performance Metrics** - Track success rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Debugging Workshop: Fix Common Prompt Problems\n",
    "\n",
    "class PromptDebugger:\n",
    "    \"\"\"A toolkit for identifying and fixing prompt issues\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.test_results = []\n",
    "        \n",
    "    def analyze_prompt(self, prompt: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze a prompt for common issues\"\"\"\n",
    "        issues = []\n",
    "        suggestions = []\n",
    "        \n",
    "        # Check for ambiguity\n",
    "        ambiguous_words = [\"it\", \"this\", \"that\", \"thing\", \"stuff\", \"whatever\"]\n",
    "        for word in ambiguous_words:\n",
    "            if word in prompt.lower():\n",
    "                issues.append(f\"Ambiguous reference: '{word}'\")\n",
    "                suggestions.append(f\"Replace '{word}' with specific nouns\")\n",
    "        \n",
    "        # Check for missing context\n",
    "        if len(prompt) < 50:\n",
    "            issues.append(\"Prompt may lack sufficient context\")\n",
    "            suggestions.append(\"Add more details about the task\")\n",
    "        \n",
    "        # Check for format specification\n",
    "        if \"format\" not in prompt.lower() and \"structure\" not in prompt.lower():\n",
    "            issues.append(\"No output format specified\")\n",
    "            suggestions.append(\"Specify desired output format explicitly\")\n",
    "        \n",
    "        return {\n",
    "            \"issues\": issues,\n",
    "            \"suggestions\": suggestions,\n",
    "            \"score\": max(0, 100 - len(issues) * 20)\n",
    "        }\n",
    "    \n",
    "    def test_consistency(self, prompt_template: PromptTemplate, test_input: str, num_runs: int = 3):\n",
    "        \"\"\"Test prompt consistency across multiple runs\"\"\"\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt_template)\n",
    "        responses = []\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            response = chain.run(test_input)\n",
    "            responses.append(response)\n",
    "            time.sleep(0.5)  # Avoid rate limiting\n",
    "        \n",
    "        # Check consistency\n",
    "        if len(set(responses)) == 1:\n",
    "            consistency = \"Perfect - Identical responses\"\n",
    "        elif len(set(responses)) == num_runs:\n",
    "            consistency = \"Poor - All responses different\"\n",
    "        else:\n",
    "            consistency = \"Moderate - Some variation\"\n",
    "        \n",
    "        return {\n",
    "            \"consistency\": consistency,\n",
    "            \"responses\": responses,\n",
    "            \"unique_responses\": len(set(responses))\n",
    "        }\n",
    "\n",
    "# Initialize debugger\n",
    "debugger = PromptDebugger(llm)\n",
    "\n",
    "print(\"üêõ PROMPT DEBUGGING EXAMPLES\\n\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 1: Bad prompt\n",
    "bad_prompt = \"Tell me about it\"\n",
    "print(\"‚ùå BAD PROMPT:\")\n",
    "print(f\"'{bad_prompt}'\\n\")\n",
    "\n",
    "analysis = debugger.analyze_prompt(bad_prompt)\n",
    "print(\"üîç Analysis:\")\n",
    "for issue in analysis[\"issues\"]:\n",
    "    print(f\"  ‚ö†Ô∏è {issue}\")\n",
    "for suggestion in analysis[\"suggestions\"]:\n",
    "    print(f\"  üí° {suggestion}\")\n",
    "print(f\"\\nüìä Quality Score: {analysis['score']}/100\\n\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 2: Improved prompt\n",
    "good_prompt = \"\"\"Analyze the following customer review and extract:\n",
    "1. Overall sentiment (positive/negative/neutral)\n",
    "2. Key product features mentioned\n",
    "3. Specific complaints or praises\n",
    "\n",
    "Format the output as a JSON object with these three keys.\n",
    "\n",
    "Review: {review}\"\"\"\n",
    "\n",
    "print(\"‚úÖ IMPROVED PROMPT:\")\n",
    "print(f\"'{good_prompt}'\\n\")\n",
    "\n",
    "analysis = debugger.analyze_prompt(good_prompt)\n",
    "print(\"üîç Analysis:\")\n",
    "if not analysis[\"issues\"]:\n",
    "    print(\"  ‚ú® No major issues detected!\")\n",
    "else:\n",
    "    for issue in analysis[\"issues\"]:\n",
    "        print(f\"  ‚ö†Ô∏è {issue}\")\n",
    "print(f\"\\nüìä Quality Score: {analysis['score']}/100\\n\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test consistency\n",
    "print(\"üîÑ TESTING PROMPT CONSISTENCY\\n\")\n",
    "\n",
    "inconsistent_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Write something creative about {topic}\"  # Too vague!\n",
    ")\n",
    "\n",
    "consistent_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"\"\"Write exactly 3 bullet points about {topic}.\n",
    "Each bullet point should:\n",
    "- Start with an emoji\n",
    "- Be exactly one sentence\n",
    "- Focus on a different aspect\"\"\"\n",
    ")\n",
    "\n",
    "print(\"Testing VAGUE prompt:\")\n",
    "vague_results = debugger.test_consistency(inconsistent_prompt, \"artificial intelligence\", 3)\n",
    "print(f\"Consistency: {vague_results['consistency']}\")\n",
    "\n",
    "print(\"\\nTesting SPECIFIC prompt:\")\n",
    "specific_results = debugger.test_consistency(consistent_prompt, \"artificial intelligence\", 3)\n",
    "print(f\"Consistency: {specific_results['consistency']}\")\n",
    "\n",
    "print(\"\\nüí° Lesson: Specific instructions lead to more consistent outputs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tua0i5wowvo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Advanced Debugging: The Prompt Doctor\n",
    "\n",
    "class PromptDoctor:\n",
    "    \"\"\"Advanced diagnostic tool for prompt engineering\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.common_diseases = {\n",
    "            \"Vagueness Virus\": {\n",
    "                \"symptoms\": [\"it\", \"this\", \"that\", \"stuff\", \"things\"],\n",
    "                \"treatment\": \"Replace pronouns with specific nouns\"\n",
    "            },\n",
    "            \"Ambiguity Ailment\": {\n",
    "                \"symptoms\": [\"maybe\", \"probably\", \"might\", \"could\", \"possibly\"],\n",
    "                \"treatment\": \"Use definitive language and clear instructions\"\n",
    "            },\n",
    "            \"Context Deficiency\": {\n",
    "                \"symptoms\": [\"prompt_length < 30\"],\n",
    "                \"treatment\": \"Add background information and constraints\"\n",
    "            },\n",
    "            \"Format Fever\": {\n",
    "                \"symptoms\": [\"missing output format specification\"],\n",
    "                \"treatment\": \"Specify exact output format with examples\"\n",
    "            },\n",
    "            \"Hallucination Syndrome\": {\n",
    "                \"symptoms\": [\"no fact-checking\", \"no sources\"],\n",
    "                \"treatment\": \"Add verification steps and source requirements\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def diagnose(self, prompt):\n",
    "        \"\"\"Run full diagnostic on a prompt\"\"\"\n",
    "        diagnosis = []\n",
    "        severity = 0\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        \n",
    "        for disease, info in self.common_diseases.items():\n",
    "            for symptom in info[\"symptoms\"]:\n",
    "                if \"prompt_length\" in symptom:\n",
    "                    if len(prompt) < 30:\n",
    "                        diagnosis.append({\n",
    "                            \"disease\": disease,\n",
    "                            \"severity\": \"high\",\n",
    "                            \"treatment\": info[\"treatment\"]\n",
    "                        })\n",
    "                        severity += 3\n",
    "                elif symptom in prompt_lower:\n",
    "                    diagnosis.append({\n",
    "                        \"disease\": disease,\n",
    "                        \"severity\": \"medium\",\n",
    "                        \"treatment\": info[\"treatment\"]\n",
    "                    })\n",
    "                    severity += 2\n",
    "        \n",
    "        health_score = max(0, 100 - (severity * 10))\n",
    "        \n",
    "        return {\n",
    "            \"health_score\": health_score,\n",
    "            \"diagnosis\": diagnosis,\n",
    "            \"status\": \"Healthy\" if health_score > 80 else \"Needs Treatment\"\n",
    "        }\n",
    "    \n",
    "    def prescribe_treatment(self, prompt, diagnosis):\n",
    "        \"\"\"Generate improved version of prompt\"\"\"\n",
    "        treatment_prompt = PromptTemplate(\n",
    "            input_variables=[\"original\", \"issues\"],\n",
    "            template=\"\"\"As a prompt engineering expert, improve this prompt.\n",
    "\n",
    "Original Prompt: {original}\n",
    "\n",
    "Issues Found: {issues}\n",
    "\n",
    "Create an improved version that:\n",
    "1. Eliminates ambiguity\n",
    "2. Adds specific context\n",
    "3. Defines clear output format\n",
    "4. Includes validation steps\n",
    "\n",
    "Improved Prompt:\"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=treatment_prompt)\n",
    "        issues_text = \"\\n\".join([f\"- {d['disease']}: {d['treatment']}\" for d in diagnosis])\n",
    "        \n",
    "        return chain.run(original=prompt, issues=issues_text)\n",
    "\n",
    "# Initialize the Prompt Doctor\n",
    "doctor = PromptDoctor(llm)\n",
    "\n",
    "print(\"üë®‚Äç‚öïÔ∏è THE PROMPT DOCTOR IS IN!\\n\")\n",
    "print(\"Let's diagnose and treat sick prompts!\\n\")\n",
    "\n",
    "# Example sick prompts\n",
    "sick_prompts = [\n",
    "    \"Tell me about it\",\n",
    "    \"Maybe explain this thing properly\",\n",
    "    \"Write something good about AI\"\n",
    "]\n",
    "\n",
    "for prompt in sick_prompts[:1]:  # Test first prompt\n",
    "    print(f\"ü§í Sick Prompt: '{prompt}'\\n\")\n",
    "    \n",
    "    # Diagnose\n",
    "    diagnosis = doctor.diagnose(prompt)\n",
    "    print(f\"üìä Health Score: {diagnosis['health_score']}/100\")\n",
    "    print(f\"üìã Status: {diagnosis['status']}\\n\")\n",
    "    \n",
    "    if diagnosis['diagnosis']:\n",
    "        print(\"üî¨ Diagnosis:\")\n",
    "        for d in diagnosis['diagnosis']:\n",
    "            print(f\"  ‚Ä¢ {d['disease']} (Severity: {d['severity']})\")\n",
    "            print(f\"    Treatment: {d['treatment']}\")\n",
    "        \n",
    "        print(\"\\nüíä Prescribing treatment...\")\n",
    "        improved = doctor.prescribe_treatment(prompt, diagnosis['diagnosis'])\n",
    "        print(f\"\\n‚ú® Improved Prompt:\\n{improved}\\n\")\n",
    "\n",
    "print(\"üí° DEBUGGING TIP: The 5-Point Checkup\")\n",
    "print(\"Before deploying any prompt, check:\")\n",
    "print(\"1. ‚úì Specific nouns (no vague pronouns)\")\n",
    "print(\"2. ‚úì Clear instructions (no ambiguity)\")\n",
    "print(\"3. ‚úì Output format specified\")\n",
    "print(\"4. ‚úì Edge cases handled\")\n",
    "print(\"5. ‚úì Success criteria defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c00129",
   "metadata": {},
   "source": [
    "## üéÆ Part 9: Interactive Challenge Zone!\n",
    "\n",
    "### **Test Your Skills!** üèÜ\n",
    "Now it's time to apply everything you've learned. Complete these challenges to become a prompt engineering master!\n",
    "\n",
    "### **Challenges:**\n",
    "1. **üß† CoT Challenge**: Solve a complex problem step-by-step\n",
    "2. **üìö Few-Shot Challenge**: Create a custom formatter\n",
    "3. **üé≠ Role Challenge**: Design a unique expert persona\n",
    "4. **üîß Debug Challenge**: Fix a broken prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a72f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÜ Challenge 1: Chain-of-Thought Master\n",
    "\n",
    "print(\"üß† CHALLENGE 1: CoT Problem Solving\\n\")\n",
    "print(\"Can you create a CoT prompt to solve this puzzle?\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "puzzle = \"\"\"\n",
    "A farmer needs to cross a river with a fox, a chicken, and a bag of grain.\n",
    "The boat can only carry the farmer and one item at a time.\n",
    "If left alone: the fox will eat the chicken, the chicken will eat the grain.\n",
    "How can the farmer get everything across safely?\n",
    "\"\"\"\n",
    "\n",
    "print(puzzle)\n",
    "print(\"\\nüìù Create your CoT prompt below:\")\n",
    "\n",
    "# Student's solution space\n",
    "your_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"puzzle\"],\n",
    "    template=\"\"\"[YOUR PROMPT HERE - Use Chain-of-Thought reasoning!]\n",
    "\n",
    "Puzzle: {puzzle}\n",
    "\n",
    "Solution:\"\"\"\n",
    ")\n",
    "\n",
    "# Uncomment to test your prompt:\n",
    "# your_chain = LLMChain(llm=llm, prompt=your_cot_prompt)\n",
    "# solution = your_chain.run(puzzle=puzzle)\n",
    "# print(\"Your AI's solution:\", solution)\n",
    "\n",
    "# Solution hint\n",
    "print(\"\\nüí° Hint: Break it down into states, moves, and constraints!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fxd6k438eo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÜ Challenge 2: Few-Shot Formatting Expert\n",
    "\n",
    "print(\"üìö CHALLENGE 2: Few-Shot Learning\\n\")\n",
    "print(\"Create a few-shot prompt that converts data between formats\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Your task: Create a few-shot prompt that converts between different data formats\n",
    "# Example: CSV to JSON, or natural language to SQL\n",
    "\n",
    "print(\"\"\"\n",
    "Your Task: Create a few-shot prompt that converts:\n",
    "Natural language queries ‚Üí SQL statements\n",
    "\n",
    "Example input: \"Show me all users who joined last month\"\n",
    "Example output: \"SELECT * FROM users WHERE join_date >= DATE_SUB(NOW(), INTERVAL 1 MONTH)\"\n",
    "\n",
    "Create at least 3 examples and test with a new query!\n",
    "\"\"\")\n",
    "\n",
    "# Student workspace\n",
    "your_examples = [\n",
    "    # Add your examples here\n",
    "    {\"input\": \"...\", \"output\": \"...\"},\n",
    "]\n",
    "\n",
    "# Build your few-shot prompt here\n",
    "# your_few_shot_prompt = FewShotPromptTemplate(...)\n",
    "\n",
    "print(\"\\nüí° Hint: Include different SQL operations (SELECT, JOIN, WHERE, GROUP BY)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22490450",
   "metadata": {},
   "source": [
    "## ü§ñ Part 10: Agentic Frameworks - Building Intelligent AI Systems\n",
    "\n",
    "### **What Makes an Agent \"Agentic\"?** üß†\n",
    "- **Autonomy**: Can make decisions independently\n",
    "- **Tool Use**: Can interact with external systems\n",
    "- **Memory**: Maintains context across interactions\n",
    "- **Planning**: Can break down complex tasks\n",
    "- **Reflection**: Can evaluate and improve its responses\n",
    "\n",
    "### **LangChain Agent Components:**\n",
    "1. **üß† LLM**: The reasoning engine\n",
    "2. **üõ†Ô∏è Tools**: Functions the agent can call\n",
    "3. **üìù Prompt**: Instructions and context\n",
    "4. **üíæ Memory**: Conversation history\n",
    "5. **üîÑ Agent Executor**: Orchestrates everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Building Your First Intelligent Agent with Advanced Prompting\n",
    "\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import hub\n",
    "\n",
    "# Define custom tools for our agent\n",
    "def calculate_tool(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate mathematical expressions\"\"\"\n",
    "    try:\n",
    "        # Only allow safe math operations\n",
    "        allowed_names = {\n",
    "            k: v for k, v in math.__dict__.items() if not k.startswith(\"__\")\n",
    "        }\n",
    "        result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "        return f\"The result is: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "def analyze_sentiment(text: str) -> str:\n",
    "    \"\"\"Analyze sentiment using role-based prompting\"\"\"\n",
    "    sentiment_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"\"\"You are a sentiment analysis expert.\n",
    "        \n",
    "Analyze the sentiment of this text:\n",
    "\"{text}\"\n",
    "\n",
    "Provide:\n",
    "1. Overall sentiment (positive/negative/neutral)\n",
    "2. Confidence score (0-100%)\n",
    "3. Key emotional indicators\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = LLMChain(llm=llm, prompt=sentiment_prompt)\n",
    "    return chain.run(text=text)\n",
    "\n",
    "def generate_code(description: str) -> str:\n",
    "    \"\"\"Generate code using CoT prompting\"\"\"\n",
    "    code_prompt = PromptTemplate(\n",
    "        input_variables=[\"description\"],\n",
    "        template=\"\"\"You are an expert programmer. Generate code step by step.\n",
    "\n",
    "Task: {description}\n",
    "\n",
    "Let's think through this:\n",
    "1. First, understand the requirements\n",
    "2. Choose the appropriate language and approach\n",
    "3. Write clean, commented code\n",
    "4. Include error handling\n",
    "\n",
    "Generated code:\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = LLMChain(llm=llm, prompt=code_prompt)\n",
    "    return chain.run(description=description)\n",
    "\n",
    "# Create tools for the agent\n",
    "import math\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=calculate_tool,\n",
    "        description=\"Useful for mathematical calculations. Input should be a valid math expression.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"SentimentAnalyzer\",\n",
    "        func=analyze_sentiment,\n",
    "        description=\"Analyzes the sentiment and emotion in text. Input should be the text to analyze.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CodeGenerator\",\n",
    "        func=generate_code,\n",
    "        description=\"Generates code based on requirements. Input should be a description of what the code should do.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create the agent with memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Custom agent prompt combining all techniques\n",
    "agent_prompt = \"\"\"You are an advanced AI assistant with access to various tools.\n",
    "\n",
    "## Your Capabilities:\n",
    "- Mathematical calculations\n",
    "- Sentiment analysis\n",
    "- Code generation\n",
    "- Complex reasoning\n",
    "\n",
    "## Instructions:\n",
    "1. Use Chain-of-Thought reasoning for complex problems\n",
    "2. Apply the appropriate tool for each task\n",
    "3. Maintain context from previous interactions\n",
    "4. Be helpful and accurate\n",
    "\n",
    "## Available Tools:\n",
    "{tools}\n",
    "\n",
    "## Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "## Current Task:\n",
    "Human: {input}\n",
    "\n",
    "## Your Approach:\n",
    "{agent_scratchpad}\n",
    "\n",
    "Think step by step about how to best help the user.\"\"\"\n",
    "\n",
    "# Initialize the agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "# Test the agent with various tasks\n",
    "print(\"ü§ñ INTELLIGENT AGENT DEMO\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_queries = [\n",
    "    \"Calculate the compound interest on $1000 at 5% for 3 years\",\n",
    "    \"Analyze the sentiment of this review: 'This product exceeded my expectations! Absolutely fantastic quality.'\",\n",
    "    \"Generate a Python function to check if a number is prime\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüìù Query: {query}\\n\")\n",
    "    try:\n",
    "        response = agent.run(query)\n",
    "        print(f\"ü§ñ Agent Response:\\n{response}\\n\")\n",
    "        print(\"-\"*60)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\n\")\n",
    "        print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76601553",
   "metadata": {},
   "source": [
    "## üöÄ Part 11: Advanced Agentic Patterns\n",
    "\n",
    "### **Production-Ready Agent Patterns** üè≠\n",
    "\n",
    "1. **üîÑ ReAct Pattern**: Reasoning + Acting in cycles\n",
    "2. **üå≥ Tree of Thoughts**: Explore multiple reasoning paths\n",
    "3. **üîç Self-Reflection**: Agent evaluates its own outputs\n",
    "4. **üìä Multi-Agent Systems**: Agents collaborating on tasks\n",
    "5. **üéØ Goal-Oriented Agents**: Working towards specific objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè≠ Advanced Agent Pattern: Self-Reflecting Research Assistant\n",
    "\n",
    "class SelfReflectingAgent:\n",
    "    \"\"\"An agent that can evaluate and improve its own responses\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.iterations = 0\n",
    "        self.max_iterations = 3\n",
    "        \n",
    "    def research(self, query: str) -> str:\n",
    "        \"\"\"Initial research phase\"\"\"\n",
    "        research_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"\"\"You are a research assistant. \n",
    "            \n",
    "Research Query: {query}\n",
    "\n",
    "Provide a comprehensive answer using:\n",
    "1. Key facts and concepts\n",
    "2. Multiple perspectives\n",
    "3. Relevant examples\n",
    "4. Potential limitations or caveats\n",
    "\n",
    "Research Response:\"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=research_prompt)\n",
    "        return chain.run(query=query)\n",
    "    \n",
    "    def reflect(self, query: str, response: str) -> Dict[str, Any]:\n",
    "        \"\"\"Reflect on the quality of the response\"\"\"\n",
    "        reflection_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"response\"],\n",
    "            template=\"\"\"Evaluate this research response critically.\n",
    "\n",
    "Original Query: {query}\n",
    "Response: {response}\n",
    "\n",
    "Evaluate based on:\n",
    "1. Accuracy - Are the facts correct?\n",
    "2. Completeness - Are important points missing?\n",
    "3. Clarity - Is it easy to understand?\n",
    "4. Relevance - Does it answer the question?\n",
    "\n",
    "Provide:\n",
    "- Quality Score (1-10)\n",
    "- Strengths (bullet points)\n",
    "- Weaknesses (bullet points)\n",
    "- Suggestions for improvement\n",
    "\n",
    "Format as JSON.\"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=reflection_prompt)\n",
    "        reflection = chain.run(query=query, response=response)\n",
    "        \n",
    "        # Parse reflection (simplified - in production use proper JSON parsing)\n",
    "        return {\n",
    "            \"reflection\": reflection,\n",
    "            \"should_improve\": \"Weaknesses\" in reflection and len(reflection) > 100\n",
    "        }\n",
    "    \n",
    "    def improve(self, query: str, original_response: str, reflection: str) -> str:\n",
    "        \"\"\"Improve the response based on reflection\"\"\"\n",
    "        improvement_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"original\", \"reflection\"],\n",
    "            template=\"\"\"Improve this research response based on the feedback.\n",
    "\n",
    "Query: {query}\n",
    "Original Response: {original}\n",
    "Feedback: {reflection}\n",
    "\n",
    "Create an improved version that addresses the weaknesses while maintaining the strengths.\n",
    "\n",
    "Improved Response:\"\"\"\n",
    "        )\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=improvement_prompt)\n",
    "        return chain.run(query=query, original=original_response, reflection=reflection)\n",
    "    \n",
    "    def execute(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the full self-reflecting research process\"\"\"\n",
    "        print(f\"üîç Researching: {query}\\n\")\n",
    "        \n",
    "        # Initial research\n",
    "        response = self.research(query)\n",
    "        print(\"üìù Initial Response Generated\\n\")\n",
    "        \n",
    "        best_response = response\n",
    "        reflections = []\n",
    "        \n",
    "        # Iterative improvement\n",
    "        for i in range(self.max_iterations):\n",
    "            print(f\"üîÑ Reflection Round {i+1}...\")\n",
    "            \n",
    "            # Reflect on current response\n",
    "            reflection_result = self.reflect(query, response)\n",
    "            reflections.append(reflection_result)\n",
    "            \n",
    "            # Check if improvement is needed\n",
    "            if reflection_result[\"should_improve\"] and i < self.max_iterations - 1:\n",
    "                print(\"  üí° Improvements identified, refining...\")\n",
    "                response = self.improve(query, response, reflection_result[\"reflection\"])\n",
    "                best_response = response\n",
    "            else:\n",
    "                print(\"  ‚úÖ Response meets quality standards\")\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"final_response\": best_response,\n",
    "            \"iterations\": i + 1,\n",
    "            \"reflections\": reflections\n",
    "        }\n",
    "\n",
    "# Create and test the self-reflecting agent\n",
    "reflecting_agent = SelfReflectingAgent(llm)\n",
    "\n",
    "# Test with a complex query\n",
    "test_query = \"What are the implications of quantum computing for cybersecurity?\"\n",
    "\n",
    "print(\"ü§ñ SELF-REFLECTING AGENT DEMO\\n\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = reflecting_agent.execute(test_query)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL RESULTS:\\n\")\n",
    "print(f\"Query: {result['query']}\\n\")\n",
    "print(f\"Iterations: {result['iterations']}\\n\")\n",
    "print(\"Final Response:\")\n",
    "print(\"-\"*40)\n",
    "print(result['final_response'])\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\nüí° This agent pattern combines:\")\n",
    "print(\"- Chain-of-Thought (research phase)\")\n",
    "print(\"- Role-based prompting (research assistant)\")\n",
    "print(\"- Self-reflection (quality evaluation)\")\n",
    "print(\"- Iterative improvement (refinement loop)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jn1dh65ajkn",
   "metadata": {},
   "source": [
    "## üéì Workshop Conclusion: Your Prompt Engineering Toolkit\n",
    "\n",
    "### **What You've Mastered Today:** ‚úÖ\n",
    "\n",
    "1. **Chain-of-Thought (CoT)** - Making AI think step-by-step\n",
    "2. **Few-Shot Learning** - Teaching by example\n",
    "3. **Role-Based Prompting** - Creating expert personas\n",
    "4. **Robust Templates** - Production-ready prompt systems\n",
    "5. **Debugging Techniques** - Fixing common failures\n",
    "6. **Agentic Frameworks** - Building intelligent AI systems\n",
    "\n",
    "### **Key Takeaways:** üí°\n",
    "\n",
    "- **Specificity beats ambiguity** - Clear instructions = better results\n",
    "- **Examples are powerful** - Show, don't just tell\n",
    "- **Roles add expertise** - Context shapes responses\n",
    "- **Iteration is key** - Test, reflect, improve\n",
    "- **Combine techniques** - Mix methods for best results\n",
    "\n",
    "### **Next Steps:** üöÄ\n",
    "\n",
    "1. **Practice** - Try these techniques on your own problems\n",
    "2. **Experiment** - Combine different approaches\n",
    "3. **Build** - Create your own AI agents\n",
    "4. **Share** - Join the prompt engineering community\n",
    "5. **Stay Updated** - This field evolves rapidly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gd8zmlwewm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Final Challenge: Build Your Own Custom Agent!\n",
    "\n",
    "print(\"üèÜ FINAL CHALLENGE: Create Your Dream AI Agent!\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Combine everything you've learned to create a custom agent that:\n",
    "1. Uses Chain-of-Thought for complex reasoning\n",
    "2. Applies Few-Shot learning for consistent outputs\n",
    "3. Adopts a specific Role/Persona\n",
    "4. Has custom tools and capabilities\n",
    "5. Can self-reflect and improve\n",
    "\n",
    "Some ideas:\n",
    "- üìö A study buddy that helps learn new topics\n",
    "- üç≥ A chef that creates recipes from ingredients\n",
    "- üíº A career coach for interview prep\n",
    "- üéÆ A game master for D&D campaigns\n",
    "- üìà A financial advisor for investments\n",
    "\"\"\")\n",
    "\n",
    "# Template for your custom agent\n",
    "class YourCustomAgent:\n",
    "    \"\"\"Replace this with your own agent implementation!\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, role, tools=None):\n",
    "        self.llm = llm\n",
    "        self.role = role\n",
    "        self.tools = tools or []\n",
    "        self.memory = []\n",
    "        \n",
    "    def think(self, task):\n",
    "        \"\"\"Add Chain-of-Thought reasoning\"\"\"\n",
    "        # Your CoT implementation\n",
    "        pass\n",
    "    \n",
    "    def learn_from_examples(self, examples):\n",
    "        \"\"\"Add Few-Shot learning\"\"\"\n",
    "        # Your few-shot implementation\n",
    "        pass\n",
    "    \n",
    "    def act(self, user_input):\n",
    "        \"\"\"Main agent action\"\"\"\n",
    "        # Combine all techniques here\n",
    "        pass\n",
    "\n",
    "# Space for your implementation\n",
    "print(\"\\nüìù Your turn to shine! Create your agent below:\")\n",
    "print(\"Uncomment and modify the template to build your dream AI assistant!\")\n",
    "\n",
    "# Example starter code\n",
    "\"\"\"\n",
    "my_agent = YourCustomAgent(\n",
    "    llm=llm,\n",
    "    role=\"Your chosen role\",\n",
    "    tools=[\"tool1\", \"tool2\"]\n",
    ")\n",
    "\n",
    "# Test your agent\n",
    "response = my_agent.act(\"Your test input\")\n",
    "print(response)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Congratulations on completing the Advanced Prompt Engineering Workshop!\")\n",
    "print(\"You're now equipped to build powerful AI applications!\")\n",
    "print(\"\\nRemember: The best way to learn is by doing. Start building! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5u16r5grk",
   "metadata": {},
   "source": [
    "## üìñ Additional Resources & Next Steps\n",
    "\n",
    "### **üìö Recommended Reading**\n",
    "- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [Anthropic's Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering)\n",
    "\n",
    "### **üõ†Ô∏è Tools & Libraries to Explore**\n",
    "- **LangSmith**: Debug and monitor LangChain applications\n",
    "- **Promptflow**: Microsoft's prompt engineering toolkit\n",
    "- **Guidance**: Structured generation library\n",
    "- **DSPy**: Declarative prompt programming\n",
    "\n",
    "### **üéØ Practice Challenges**\n",
    "1. Build a multi-lingual translator using few-shot examples\n",
    "2. Create a code reviewer that uses CoT to explain issues\n",
    "3. Design a creative writing assistant with multiple personas\n",
    "4. Implement a fact-checker that self-reflects on accuracy\n",
    "\n",
    "### **üåü Community & Support**\n",
    "- Join the [LangChain Discord](https://discord.gg/langchain)\n",
    "- Follow [r/PromptEngineering](https://reddit.com/r/promptengineering)\n",
    "- Share your work on GitHub with #promptengineering\n",
    "\n",
    "### **üìù Workshop Feedback**\n",
    "We'd love to hear about your experience! Consider:\n",
    "- What techniques worked best for you?\n",
    "- What challenges did you face?\n",
    "- What would you like to learn next?\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for participating in this Advanced Prompt Engineering Workshop!** üéâ\n",
    "\n",
    "Remember: The key to mastery is practice. Start small, experiment often, and don't be afraid to push boundaries. The future of AI interaction is in your hands!\n",
    "\n",
    "Happy prompting! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786ml5dlaa",
   "metadata": {},
   "source": [
    "## üìö Best Practices & Pro Tips\n",
    "\n",
    "### **üèÜ Golden Rules of Prompt Engineering**\n",
    "\n",
    "1. **Start Simple, Then Iterate**\n",
    "   - Begin with a basic prompt\n",
    "   - Test and identify weaknesses\n",
    "   - Add complexity gradually\n",
    "\n",
    "2. **Be Explicit About Format**\n",
    "   - Specify output structure (JSON, bullet points, paragraphs)\n",
    "   - Provide format examples\n",
    "   - Use delimiters for clarity\n",
    "\n",
    "3. **Context is King**\n",
    "   - Provide relevant background\n",
    "   - Define technical terms\n",
    "   - Set clear boundaries\n",
    "\n",
    "4. **Test Edge Cases**\n",
    "   - Empty inputs\n",
    "   - Very long inputs\n",
    "   - Special characters\n",
    "   - Contradictory instructions\n",
    "\n",
    "5. **Version Control Your Prompts**\n",
    "   - Track changes over time\n",
    "   - Document what works\n",
    "   - A/B test variations\n",
    "\n",
    "### **‚ö° Performance Optimization Tips**\n",
    "\n",
    "- **Token Management**: Keep prompts concise to reduce costs\n",
    "- **Caching**: Store common responses to avoid repeated API calls\n",
    "- **Batch Processing**: Group similar requests together\n",
    "- **Async Operations**: Use async/await for concurrent requests\n",
    "- **Rate Limiting**: Implement backoff strategies\n",
    "\n",
    "### **üõ°Ô∏è Security Considerations**\n",
    "\n",
    "- Never include sensitive data in prompts\n",
    "- Validate and sanitize user inputs\n",
    "- Implement prompt injection prevention\n",
    "- Use environment variables for API keys\n",
    "- Monitor for unusual usage patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv27pg9ct1j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíº Real-World Example: Production-Ready Prompt System\n",
    "\n",
    "class ProductionPromptSystem:\n",
    "    \"\"\"A production-ready prompt engineering system with all best practices\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, cache_enabled=True):\n",
    "        self.llm = llm\n",
    "        self.cache = {} if cache_enabled else None\n",
    "        self.prompt_versions = {}\n",
    "        self.metrics = {\n",
    "            \"total_requests\": 0,\n",
    "            \"cache_hits\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"avg_response_time\": 0\n",
    "        }\n",
    "    \n",
    "    def create_versioned_prompt(self, name: str, template: str, version: str = \"1.0.0\"):\n",
    "        \"\"\"Create and version a prompt template\"\"\"\n",
    "        if name not in self.prompt_versions:\n",
    "            self.prompt_versions[name] = {}\n",
    "        \n",
    "        self.prompt_versions[name][version] = PromptTemplate(\n",
    "            input_variables=self._extract_variables(template),\n",
    "            template=template\n",
    "        )\n",
    "        return f\"Prompt '{name}' v{version} created\"\n",
    "    \n",
    "    def _extract_variables(self, template: str) -> List[str]:\n",
    "        \"\"\"Extract variables from template string\"\"\"\n",
    "        import re\n",
    "        return list(set(re.findall(r'\\{(\\w+)\\}', template)))\n",
    "    \n",
    "    def execute_with_fallback(self, prompt_name: str, inputs: Dict, \n",
    "                            version: str = None, fallback_model: str = \"gpt-3.5-turbo\"):\n",
    "        \"\"\"Execute prompt with automatic fallback on failure\"\"\"\n",
    "        start_time = time.time()\n",
    "        self.metrics[\"total_requests\"] += 1\n",
    "        \n",
    "        # Check cache first\n",
    "        cache_key = f\"{prompt_name}:{str(inputs)}\"\n",
    "        if self.cache and cache_key in self.cache:\n",
    "            self.metrics[\"cache_hits\"] += 1\n",
    "            return self.cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            # Get the appropriate prompt version\n",
    "            if version:\n",
    "                prompt = self.prompt_versions[prompt_name][version]\n",
    "            else:\n",
    "                # Use latest version\n",
    "                versions = list(self.prompt_versions[prompt_name].keys())\n",
    "                prompt = self.prompt_versions[prompt_name][versions[-1]]\n",
    "            \n",
    "            # Execute with primary model\n",
    "            chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "            response = chain.run(**inputs)\n",
    "            \n",
    "            # Cache successful response\n",
    "            if self.cache is not None:\n",
    "                self.cache[cache_key] = response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Primary model failed: {e}\")\n",
    "            self.metrics[\"errors\"] += 1\n",
    "            \n",
    "            # Fallback to simpler model\n",
    "            try:\n",
    "                print(f\"üîÑ Falling back to {fallback_model}...\")\n",
    "                fallback_llm = ChatOpenAI(model=fallback_model, temperature=0.7)\n",
    "                chain = LLMChain(llm=fallback_llm, prompt=prompt)\n",
    "                response = chain.run(**inputs)\n",
    "            except Exception as fallback_error:\n",
    "                return f\"Error: Both primary and fallback models failed - {fallback_error}\"\n",
    "        \n",
    "        # Update metrics\n",
    "        elapsed = time.time() - start_time\n",
    "        self.metrics[\"avg_response_time\"] = (\n",
    "            (self.metrics[\"avg_response_time\"] * (self.metrics[\"total_requests\"] - 1) + elapsed) \n",
    "            / self.metrics[\"total_requests\"]\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_metrics(self) -> Dict:\n",
    "        \"\"\"Get system metrics\"\"\"\n",
    "        return {\n",
    "            **self.metrics,\n",
    "            \"cache_size\": len(self.cache) if self.cache else 0,\n",
    "            \"prompt_versions\": {k: list(v.keys()) for k, v in self.prompt_versions.items()}\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "print(\"üè≠ Production Prompt System Demo\\n\")\n",
    "\n",
    "# Initialize the system\n",
    "prod_system = ProductionPromptSystem(llm, cache_enabled=True)\n",
    "\n",
    "# Create versioned prompts\n",
    "prod_system.create_versioned_prompt(\n",
    "    \"analyzer\",\n",
    "    \"Analyze this text and provide insights: {text}\",\n",
    "    \"1.0.0\"\n",
    ")\n",
    "\n",
    "prod_system.create_versioned_prompt(\n",
    "    \"analyzer\",\n",
    "    \"\"\"Analyze this text with the following focus:\n",
    "    \n",
    "Text: {text}\n",
    "\n",
    "Provide:\n",
    "1. Main themes\n",
    "2. Sentiment\n",
    "3. Key takeaways\n",
    "\n",
    "Format as bullet points.\"\"\",\n",
    "    \"2.0.0\"\n",
    ")\n",
    "\n",
    "# Test the system\n",
    "test_text = \"Artificial intelligence is transforming how we work and live.\"\n",
    "\n",
    "print(\"üìä Testing versioned prompts:\\n\")\n",
    "response_v1 = prod_system.execute_with_fallback(\n",
    "    \"analyzer\", \n",
    "    {\"text\": test_text},\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "print(f\"Version 1.0.0 Response:\\n{response_v1}\\n\")\n",
    "\n",
    "response_v2 = prod_system.execute_with_fallback(\n",
    "    \"analyzer\",\n",
    "    {\"text\": test_text},\n",
    "    version=\"2.0.0\"\n",
    ")\n",
    "print(f\"Version 2.0.0 Response:\\n{response_v2}\\n\")\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nüìà System Metrics:\")\n",
    "metrics = prod_system.get_metrics()\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v8qohif7c2",
   "metadata": {},
   "source": [
    "## üöÄ Project Ideas: Build Your Own Agentic AI Systems!\n",
    "\n",
    "### **üéØ Beginner Projects (Start Here!)**\n",
    "\n",
    "#### 1. **üìù Smart Note-Taking Agent**\n",
    "- **Goal**: Build an agent that captures, organizes, and retrieves notes intelligently\n",
    "- **Features**:\n",
    "  - Auto-categorize notes using few-shot learning\n",
    "  - Summarize long notes with CoT\n",
    "  - Search notes semantically\n",
    "  - Generate study guides from notes\n",
    "- **Tech Stack**: LangChain + Vector DB (Chroma/Pinecone)\n",
    "- **Challenge**: Add voice-to-note transcription!\n",
    "\n",
    "#### 2. **üéÆ Interactive Story Game Master**\n",
    "- **Goal**: Create a D&D-style game master that adapts to player choices\n",
    "- **Features**:\n",
    "  - Dynamic story generation with role-based prompting\n",
    "  - Character personality management\n",
    "  - Combat system with CoT calculations\n",
    "  - World state tracking with memory\n",
    "- **Tech Stack**: LangChain + ConversationBufferMemory\n",
    "- **Challenge**: Add image generation for scenes!\n",
    "\n",
    "#### 3. **üç≥ Meal Planning Assistant**\n",
    "- **Goal**: Agent that plans weekly meals based on preferences and budget\n",
    "- **Features**:\n",
    "  - Recipe generation from available ingredients (few-shot)\n",
    "  - Nutritional analysis with CoT\n",
    "  - Shopping list optimization\n",
    "  - Dietary restriction handling\n",
    "- **Tech Stack**: LangChain + Custom Tools\n",
    "- **Challenge**: Integrate with grocery delivery APIs!\n",
    "\n",
    "### **üîß Intermediate Projects**\n",
    "\n",
    "#### 4. **üíª Code Review & Refactoring Agent**\n",
    "- **Goal**: Intelligent code analyzer that suggests improvements\n",
    "- **Features**:\n",
    "  - Multi-file code analysis with CoT\n",
    "  - Pattern detection using few-shot examples\n",
    "  - Security vulnerability scanning\n",
    "  - Auto-generate unit tests\n",
    "  - Refactoring suggestions with explanations\n",
    "- **Tech Stack**: LangChain + AST parsing + GitHub API\n",
    "- **Challenge**: Create PR comments automatically!\n",
    "\n",
    "#### 5. **üìä Data Analysis Copilot**\n",
    "- **Goal**: Agent that helps analyze datasets and generate insights\n",
    "- **Features**:\n",
    "  - Natural language to SQL/Pandas (few-shot)\n",
    "  - Statistical analysis with CoT reasoning\n",
    "  - Visualization recommendations\n",
    "  - Anomaly detection and explanation\n",
    "- **Tech Stack**: LangChain + Pandas + Plotly\n",
    "- **Challenge**: Add predictive modeling suggestions!\n",
    "\n",
    "#### 6. **üéì Personalized Learning Tutor**\n",
    "- **Goal**: Adaptive tutor that adjusts to student learning style\n",
    "- **Features**:\n",
    "  - Knowledge assessment with CoT\n",
    "  - Personalized explanation generation (role-based)\n",
    "  - Practice problem generation (few-shot)\n",
    "  - Progress tracking and reporting\n",
    "  - Multiple teaching strategies\n",
    "- **Tech Stack**: LangChain + Knowledge Graph\n",
    "- **Challenge**: Add spaced repetition scheduling!\n",
    "\n",
    "### **üöÄ Advanced Projects**\n",
    "\n",
    "#### 7. **ü§ù Multi-Agent Customer Support System**\n",
    "- **Goal**: Team of specialized agents handling customer queries\n",
    "- **Features**:\n",
    "  - Router agent (classifies queries)\n",
    "  - Technical support agent (CoT troubleshooting)\n",
    "  - Billing agent (database integration)\n",
    "  - Escalation agent (complex issues)\n",
    "  - Supervisor agent (quality control)\n",
    "- **Tech Stack**: LangChain + Multi-Agent Framework + CRM Integration\n",
    "- **Challenge**: Add sentiment-based routing!\n",
    "\n",
    "#### 8. **üî¨ Research Assistant Network**\n",
    "- **Goal**: Collaborative agents for academic research\n",
    "- **Features**:\n",
    "  - Literature review agent (summarization)\n",
    "  - Hypothesis generator (creative CoT)\n",
    "  - Experiment designer (methodological reasoning)\n",
    "  - Data analyzer (statistical CoT)\n",
    "  - Paper writer (structured generation)\n",
    "- **Tech Stack**: LangChain + Arxiv API + Citation Management\n",
    "- **Challenge**: Add peer review simulation!\n",
    "\n",
    "#### 9. **üè¢ Business Intelligence Dashboard**\n",
    "- **Goal**: Executive assistant for business metrics and decisions\n",
    "- **Features**:\n",
    "  - KPI monitoring with explanations\n",
    "  - Competitive analysis (web scraping + analysis)\n",
    "  - Market trend prediction (CoT reasoning)\n",
    "  - Report generation (template-based)\n",
    "  - What-if scenario modeling\n",
    "- **Tech Stack**: LangChain + BI Tools + Real-time Data Feeds\n",
    "- **Challenge**: Add voice-activated queries!\n",
    "\n",
    "### **üåü Expert-Level Projects**\n",
    "\n",
    "#### 10. **üß† Self-Improving Documentation System**\n",
    "- **Goal**: Agent that writes and maintains documentation autonomously\n",
    "- **Features**:\n",
    "  - Code-to-documentation generation\n",
    "  - Documentation quality scoring\n",
    "  - Self-reflection and improvement\n",
    "  - Version-aware updates\n",
    "  - Multi-language support\n",
    "- **Implementation Tips**:\n",
    "  ```python\n",
    "  # Self-reflection loop\n",
    "  1. Generate documentation\n",
    "  2. Evaluate quality (separate prompt)\n",
    "  3. Identify weaknesses\n",
    "  4. Regenerate with improvements\n",
    "  5. Compare versions and select best\n",
    "  ```\n",
    "\n",
    "#### 11. **üéØ Autonomous Project Manager**\n",
    "- **Goal**: AI that manages software projects end-to-end\n",
    "- **Features**:\n",
    "  - Requirement analysis (CoT breakdown)\n",
    "  - Task decomposition and estimation\n",
    "  - Resource allocation optimization\n",
    "  - Risk assessment and mitigation\n",
    "  - Progress tracking and reporting\n",
    "  - Stakeholder communication drafts\n",
    "- **Tech Stack**: LangChain + Jira API + Slack + Calendar Integration\n",
    "\n",
    "#### 12. **üîÆ Predictive Debugging Assistant**\n",
    "- **Goal**: Predict and prevent bugs before they happen\n",
    "- **Features**:\n",
    "  - Code pattern analysis for bug prediction\n",
    "  - Test coverage gap identification\n",
    "  - Performance bottleneck detection\n",
    "  - Security vulnerability scanning\n",
    "  - Automated fix suggestions with explanations\n",
    "- **Tech Stack**: LangChain + Static Analysis Tools + ML Models\n",
    "\n",
    "### **üí° Implementation Tips for All Projects**\n",
    "\n",
    "#### **Architecture Best Practices:**\n",
    "```python\n",
    "# 1. Modular Agent Design\n",
    "class BaseAgent:\n",
    "    def __init__(self, llm, tools, memory):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.memory = memory\n",
    "    \n",
    "    def process(self, input):\n",
    "        # Standard processing pipeline\n",
    "        pass\n",
    "\n",
    "# 2. Prompt Versioning\n",
    "prompts = {\n",
    "    \"v1.0\": \"Basic prompt\",\n",
    "    \"v1.1\": \"Improved with CoT\",\n",
    "    \"v2.0\": \"Added few-shot examples\"\n",
    "}\n",
    "\n",
    "# 3. Error Handling\n",
    "try:\n",
    "    response = agent.run(query)\n",
    "except Exception as e:\n",
    "    fallback_response = simple_agent.run(query)\n",
    "    log_error(e)\n",
    "\n",
    "# 4. Performance Monitoring\n",
    "@track_performance\n",
    "def agent_action(input):\n",
    "    start = time.time()\n",
    "    result = process(input)\n",
    "    log_metrics(time.time() - start)\n",
    "    return result\n",
    "```\n",
    "\n",
    "#### **Testing Strategies:**\n",
    "- **Unit Testing**: Test individual prompts and tools\n",
    "- **Integration Testing**: Test agent chains end-to-end\n",
    "- **Regression Testing**: Ensure improvements don't break existing functionality\n",
    "- **A/B Testing**: Compare different prompt strategies\n",
    "- **User Testing**: Get feedback on agent responses\n",
    "\n",
    "#### **Scaling Considerations:**\n",
    "1. **Caching**: Store common responses to reduce API calls\n",
    "2. **Async Processing**: Handle multiple requests concurrently\n",
    "3. **Rate Limiting**: Implement backoff strategies\n",
    "4. **Cost Optimization**: Use smaller models for simple tasks\n",
    "5. **Monitoring**: Track token usage and response times\n",
    "\n",
    "### **üé™ Fun Variations & Challenges**\n",
    "\n",
    "#### **Make It Social:**\n",
    "- Add personality traits to agents\n",
    "- Create agent debates/discussions\n",
    "- Build agent teaching agent scenarios\n",
    "- Implement agent collaboration protocols\n",
    "\n",
    "#### **Gamification Ideas:**\n",
    "- Points system for agent performance\n",
    "- Leaderboards for multi-agent systems\n",
    "- Achievement unlocks for capabilities\n",
    "- Evolution system (agents improve over time)\n",
    "\n",
    "#### **Creative Twists:**\n",
    "- **Time Traveler Agent**: Responds as if from different time periods\n",
    "- **Multilingual Mediator**: Translates and cultural adapts\n",
    "- **Dream Interpreter**: Analyzes and explains dreams with symbolism\n",
    "- **Code Poetry Generator**: Turns code into poetry and vice versa\n",
    "- **Conspiracy Theory Debunker**: Uses CoT to analyze claims\n",
    "\n",
    "### **üìö Resources for Building**\n",
    "\n",
    "#### **Frameworks & Libraries:**\n",
    "- **LangChain**: Main framework for agent development\n",
    "- **AutoGen**: Microsoft's multi-agent framework\n",
    "- **CrewAI**: High-level agent collaboration\n",
    "- **BabyAGI**: Autonomous task management\n",
    "- **AutoGPT**: Fully autonomous agents\n",
    "\n",
    "#### **Vector Databases:**\n",
    "- **Pinecone**: Managed vector database\n",
    "- **Chroma**: Open-source embeddings DB\n",
    "- **Weaviate**: GraphQL-based vector search\n",
    "- **Qdrant**: High-performance vector similarity\n",
    "\n",
    "#### **Useful APIs:**\n",
    "- **Serper**: Google search API for agents\n",
    "- **Wolfram Alpha**: Computational knowledge\n",
    "- **OpenWeather**: Weather data\n",
    "- **NewsAPI**: News aggregation\n",
    "- **GitHub API**: Code repository access\n",
    "\n",
    "### **üèÜ Success Metrics**\n",
    "\n",
    "Track your agent's performance with:\n",
    "1. **Response Accuracy**: How often is the agent correct?\n",
    "2. **Task Completion Rate**: % of tasks successfully completed\n",
    "3. **User Satisfaction**: Feedback scores\n",
    "4. **Response Time**: Average processing duration\n",
    "5. **Token Efficiency**: Output quality per token used\n",
    "6. **Error Rate**: Frequency of failures\n",
    "7. **Learning Curve**: Improvement over time\n",
    "\n",
    "### **üöÄ Next Steps**\n",
    "\n",
    "1. **Pick a project** that excites you\n",
    "2. **Start simple** - build an MVP first\n",
    "3. **Iterate quickly** - test and improve\n",
    "4. **Share your work** - get community feedback\n",
    "5. **Combine projects** - create agent ecosystems!\n",
    "\n",
    "Remember: The best agent is one that solves a real problem you care about! üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
